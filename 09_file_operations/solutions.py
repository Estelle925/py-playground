#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–‡ä»¶æ“ä½œç»ƒä¹ é¢˜å‚è€ƒç­”æ¡ˆ

æœ¬æ–‡ä»¶åŒ…å«äº†Pythonæ–‡ä»¶æ“ä½œç»ƒä¹ é¢˜çš„å‚è€ƒç­”æ¡ˆï¼Œæ¶µç›–ï¼š
1. åŸºç¡€æ–‡ä»¶æ“ä½œ
2. æ–‡æœ¬æ–‡ä»¶å¤„ç†
3. äºŒè¿›åˆ¶æ–‡ä»¶å¤„ç†
4. æ–‡ä»¶ç³»ç»Ÿæ“ä½œ
5. é«˜çº§æ–‡ä»¶æ“ä½œ
6. ç»¼åˆåº”ç”¨

ä½œè€…ï¼šPythonå­¦ä¹ åŠ©æ‰‹
æ—¥æœŸï¼š2024å¹´
"""

import os
import sys
import json
import csv
import pickle
import shutil
import tempfile
import zipfile
import tarfile
from pathlib import Path
from datetime import datetime
import hashlib
import mimetypes
from typing import Iterator, List, Dict, Any, Optional, Union
import threading
import time
import re
from collections import defaultdict, Counter
import sqlite3

print("æ–‡ä»¶æ“ä½œç»ƒä¹ é¢˜å‚è€ƒç­”æ¡ˆ")
print("=" * 50)

# ============================================================================
# 1. åŸºç¡€æ–‡ä»¶æ“ä½œç»ƒä¹ ç­”æ¡ˆ
# ============================================================================

print("\n1. åŸºç¡€æ–‡ä»¶æ“ä½œç»ƒä¹ ç­”æ¡ˆ")
print("-" * 30)

# ç»ƒä¹  1.1: æ–‡ä»¶è¯»å†™åŸºç¡€
print("\nç»ƒä¹  1.1: æ–‡ä»¶è¯»å†™åŸºç¡€")

def file_reader_writer_demo():
    """æ–‡ä»¶è¯»å†™åŸºç¡€æ¼”ç¤º"""
    filename = 'demo_file.txt'
    
    # 1. åˆ›å»ºæ–‡ä»¶å¹¶å†™å…¥å†…å®¹
    print("1. åˆ›å»ºæ–‡ä»¶å¹¶å†™å…¥å†…å®¹")
    content = [
        "è¿™æ˜¯ç¬¬ä¸€è¡Œå†…å®¹\n",
        "è¿™æ˜¯ç¬¬äºŒè¡Œå†…å®¹\n",
        "è¿™æ˜¯ç¬¬ä¸‰è¡Œå†…å®¹\n",
        "è¿™æ˜¯ç¬¬å››è¡Œå†…å®¹\n",
        "è¿™æ˜¯ç¬¬äº”è¡Œå†…å®¹\n"
    ]
    
    with open(filename, 'w', encoding='utf-8') as f:
        f.writelines(content)
    print(f"å·²åˆ›å»ºæ–‡ä»¶ {filename}")
    
    # 2. è¯»å–æ•´ä¸ªæ–‡ä»¶å†…å®¹
    print("\n2. è¯»å–æ•´ä¸ªæ–‡ä»¶å†…å®¹")
    with open(filename, 'r', encoding='utf-8') as f:
        full_content = f.read()
    print(f"æ–‡ä»¶å†…å®¹ï¼š\n{full_content}")
    
    # 3. é€è¡Œè¯»å–æ–‡ä»¶å†…å®¹
    print("3. é€è¡Œè¯»å–æ–‡ä»¶å†…å®¹")
    with open(filename, 'r', encoding='utf-8') as f:
        for line_num, line in enumerate(f, 1):
            print(f"ç¬¬{line_num}è¡Œ: {line.rstrip()}")
    
    # 4. å°†æ–‡ä»¶å†…å®¹è¯»å–åˆ°åˆ—è¡¨
    print("\n4. å°†æ–‡ä»¶å†…å®¹è¯»å–åˆ°åˆ—è¡¨")
    with open(filename, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    print(f"æ–‡ä»¶è¡Œæ•°: {len(lines)}")
    print(f"åˆ—è¡¨å†…å®¹: {[line.rstrip() for line in lines]}")
    
    # 5. è¿½åŠ å†…å®¹
    print("\n5. è¿½åŠ å†…å®¹")
    with open(filename, 'a', encoding='utf-8') as f:
        f.write("è¿™æ˜¯è¿½åŠ çš„ç¬¬å…­è¡Œå†…å®¹\n")
        f.write("è¿™æ˜¯è¿½åŠ çš„ç¬¬ä¸ƒè¡Œå†…å®¹\n")
    print("å·²è¿½åŠ ä¸¤è¡Œå†…å®¹")
    
    # 6. å†æ¬¡è¯»å–æ•´ä¸ªæ–‡ä»¶
    print("\n6. å†æ¬¡è¯»å–æ•´ä¸ªæ–‡ä»¶")
    with open(filename, 'r', encoding='utf-8') as f:
        updated_content = f.read()
    print(f"æ›´æ–°åçš„æ–‡ä»¶å†…å®¹ï¼š\n{updated_content}")
    
    # æ¸…ç†
    os.remove(filename)
    print(f"å·²åˆ é™¤æ–‡ä»¶ {filename}")

file_reader_writer_demo()

# ç»ƒä¹  1.2: æ–‡ä»¶æŒ‡é’ˆæ“ä½œ
print("\n\nç»ƒä¹  1.2: æ–‡ä»¶æŒ‡é’ˆæ“ä½œ")

def file_pointer_demo():
    """æ–‡ä»¶æŒ‡é’ˆæ“ä½œæ¼”ç¤º"""
    filename = 'pointer_demo.txt'
    
    # 1. åˆ›å»ºæ–‡ä»¶
    content = """ç¬¬ä¸€è¡Œï¼šè¿™æ˜¯ä¸€ä¸ªå¤šè¡Œæ–‡æœ¬æ–‡ä»¶
ç¬¬äºŒè¡Œï¼šç”¨äºæ¼”ç¤ºæ–‡ä»¶æŒ‡é’ˆæ“ä½œ
ç¬¬ä¸‰è¡Œï¼šåŒ…å«ä¸­æ–‡å’Œè‹±æ–‡å†…å®¹
ç¬¬å››è¡Œï¼šHello, World!
ç¬¬äº”è¡Œï¼šæ–‡ä»¶æŒ‡é’ˆæ“ä½œç¤ºä¾‹"""
    
    with open(filename, 'w', encoding='utf-8') as f:
        f.write(content)
    print(f"å·²åˆ›å»ºæ–‡ä»¶ {filename}")
    
    with open(filename, 'r', encoding='utf-8') as f:
        # 2. è¯»å–å‰10ä¸ªå­—ç¬¦
        print("\n2. è¯»å–å‰10ä¸ªå­—ç¬¦")
        first_10_chars = f.read(10)
        print(f"å‰10ä¸ªå­—ç¬¦: {repr(first_10_chars)}")
        
        # 3. è·å–å½“å‰æ–‡ä»¶æŒ‡é’ˆä½ç½®
        print("\n3. å½“å‰æ–‡ä»¶æŒ‡é’ˆä½ç½®")
        current_pos = f.tell()
        print(f"å½“å‰ä½ç½®: {current_pos}")
        
        # 4. ç§»åŠ¨åˆ°æ–‡ä»¶å¼€å¤´ï¼Œè¯»å–5ä¸ªå­—ç¬¦
        print("\n4. ç§»åŠ¨åˆ°æ–‡ä»¶å¼€å¤´ï¼Œè¯»å–5ä¸ªå­—ç¬¦")
        f.seek(0)
        first_5_chars = f.read(5)
        print(f"å‰5ä¸ªå­—ç¬¦: {repr(first_5_chars)}")
        print(f"ç§»åŠ¨åä½ç½®: {f.tell()}")
        
        # 5. ç§»åŠ¨åˆ°æ–‡ä»¶ä¸­é—´ä½ç½®
        print("\n5. ç§»åŠ¨åˆ°æ–‡ä»¶ä¸­é—´ä½ç½®")
        f.seek(0, 2)  # ç§»åŠ¨åˆ°æ–‡ä»¶æœ«å°¾
        file_size = f.tell()
        middle_pos = file_size // 2
        f.seek(middle_pos)
        print(f"æ–‡ä»¶å¤§å°: {file_size}, ä¸­é—´ä½ç½®: {middle_pos}")
        
        # è¯»å–è¯¥ä½ç½®å¼€å§‹çš„ä¸€è¡Œ
        remaining = f.read()
        first_line_from_middle = remaining.split('\n')[0]
        print(f"ä»ä¸­é—´ä½ç½®å¼€å§‹çš„å†…å®¹: {repr(first_line_from_middle)}")
        
        # 6. ç§»åŠ¨åˆ°æ–‡ä»¶æœ«å°¾å°è¯•è¯»å–
        print("\n6. ç§»åŠ¨åˆ°æ–‡ä»¶æœ«å°¾å°è¯•è¯»å–")
        f.seek(0, 2)
        end_content = f.read()
        print(f"æ–‡ä»¶æœ«å°¾è¯»å–ç»“æœ: {repr(end_content)} (ç©ºå­—ç¬¦ä¸²ï¼Œå› ä¸ºå·²åˆ°æ–‡ä»¶æœ«å°¾)")
        
        # 7. è®¡ç®—æ–‡ä»¶æ€»å­—èŠ‚æ•°
        print("\n7. è®¡ç®—æ–‡ä»¶æ€»å­—èŠ‚æ•°")
        f.seek(0, 2)
        total_bytes = f.tell()
        print(f"æ–‡ä»¶æ€»å­—èŠ‚æ•°: {total_bytes}")
    
    # æ¸…ç†
    os.remove(filename)
    print(f"å·²åˆ é™¤æ–‡ä»¶ {filename}")

file_pointer_demo()

# ç»ƒä¹  1.3: å®‰å…¨çš„æ–‡ä»¶æ“ä½œ
print("\n\nç»ƒä¹  1.3: å®‰å…¨çš„æ–‡ä»¶æ“ä½œ")

def safe_read(filename: str) -> tuple[bool, str]:
    """å®‰å…¨åœ°è¯»å–æ–‡ä»¶å†…å®¹
    
    Args:
        filename: æ–‡ä»¶å
        
    Returns:
        (æˆåŠŸæ ‡å¿—, å†…å®¹æˆ–é”™è¯¯ä¿¡æ¯)
    """
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            content = f.read()
        return True, content
    except FileNotFoundError:
        return False, f"æ–‡ä»¶ä¸å­˜åœ¨: {filename}"
    except PermissionError:
        return False, f"æ²¡æœ‰æƒé™è¯»å–æ–‡ä»¶: {filename}"
    except UnicodeDecodeError as e:
        return False, f"æ–‡ä»¶ç¼–ç é”™è¯¯: {e}"
    except Exception as e:
        return False, f"è¯»å–æ–‡ä»¶æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}"

def safe_write(filename: str, content: str) -> tuple[bool, str]:
    """å®‰å…¨åœ°å†™å…¥æ–‡ä»¶å†…å®¹
    
    Args:
        filename: æ–‡ä»¶å
        content: è¦å†™å…¥çš„å†…å®¹
        
    Returns:
        (æˆåŠŸæ ‡å¿—, æˆåŠŸæˆ–é”™è¯¯ä¿¡æ¯)
    """
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(content)
        return True, f"æˆåŠŸå†™å…¥æ–‡ä»¶: {filename}"
    except PermissionError:
        return False, f"æ²¡æœ‰æƒé™å†™å…¥æ–‡ä»¶: {filename}"
    except OSError as e:
        return False, f"å†™å…¥æ–‡ä»¶æ—¶å‘ç”Ÿç³»ç»Ÿé”™è¯¯: {e}"
    except Exception as e:
        return False, f"å†™å…¥æ–‡ä»¶æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}"

def test_safe_file_operations():
    """æµ‹è¯•å®‰å…¨æ–‡ä»¶æ“ä½œå‡½æ•°"""
    print("æµ‹è¯•å®‰å…¨æ–‡ä»¶æ“ä½œå‡½æ•°")
    
    # æµ‹è¯•å†™å…¥æ–‡ä»¶
    test_content = "è¿™æ˜¯æµ‹è¯•å†…å®¹\nåŒ…å«å¤šè¡Œæ–‡æœ¬\nç”¨äºæµ‹è¯•å®‰å…¨æ–‡ä»¶æ“ä½œ"
    success, message = safe_write('test_safe.txt', test_content)
    print(f"å†™å…¥æµ‹è¯•: {message}")
    
    if success:
        # æµ‹è¯•è¯»å–å­˜åœ¨çš„æ–‡ä»¶
        success, content = safe_read('test_safe.txt')
        if success:
            print(f"è¯»å–æˆåŠŸï¼Œå†…å®¹é•¿åº¦: {len(content)}")
            print(f"å†…å®¹é¢„è§ˆ: {repr(content[:50])}...")
        else:
            print(f"è¯»å–å¤±è´¥: {content}")
        
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        os.remove('test_safe.txt')
    
    # æµ‹è¯•è¯»å–ä¸å­˜åœ¨çš„æ–‡ä»¶
    success, message = safe_read('nonexistent_file.txt')
    print(f"è¯»å–ä¸å­˜åœ¨æ–‡ä»¶æµ‹è¯•: {message}")
    
    # æµ‹è¯•å†™å…¥åˆ°åªè¯»ç›®å½•ï¼ˆå¦‚æœå¯èƒ½ï¼‰
    try:
        success, message = safe_write('/root/test.txt', 'test')
        print(f"å†™å…¥å—é™ç›®å½•æµ‹è¯•: {message}")
    except:
        print("å†™å…¥å—é™ç›®å½•æµ‹è¯•: æ— æ³•æµ‹è¯•ï¼ˆæƒé™é™åˆ¶ï¼‰")

test_safe_file_operations()

# ============================================================================
# 2. æ–‡æœ¬æ–‡ä»¶å¤„ç†ç»ƒä¹ ç­”æ¡ˆ
# ============================================================================

print("\n\n2. æ–‡æœ¬æ–‡ä»¶å¤„ç†ç»ƒä¹ ç­”æ¡ˆ")
print("-" * 30)

# ç»ƒä¹  2.1: CSVæ–‡ä»¶å¤„ç†
print("\nç»ƒä¹  2.1: CSVæ–‡ä»¶å¤„ç†")

def csv_processor_demo():
    """CSVæ–‡ä»¶å¤„ç†æ¼”ç¤º"""
    filename = 'employees.csv'
    
    # 1. åˆ›å»ºCSVæ–‡ä»¶
    print("1. åˆ›å»ºCSVæ–‡ä»¶")
    employees_data = [
        ['å§“å', 'å¹´é¾„', 'åŸå¸‚', 'èŒä¸š'],
        ['å¼ ä¸‰', '25', 'åŒ—äº¬', 'è½¯ä»¶å·¥ç¨‹å¸ˆ'],
        ['æå››', '30', 'ä¸Šæµ·', 'äº§å“ç»ç†'],
        ['ç‹äº”', '28', 'å¹¿å·', 'æ•°æ®åˆ†æå¸ˆ'],
        ['èµµå…­', '35', 'æ·±åœ³', 'æ¶æ„å¸ˆ'],
        ['é’±ä¸ƒ', '26', 'åŒ—äº¬', 'å‰ç«¯å·¥ç¨‹å¸ˆ'],
        ['å­™å…«', '32', 'ä¸Šæµ·', 'è¿ç»´å·¥ç¨‹å¸ˆ']
    ]
    
    with open(filename, 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerows(employees_data)
    print(f"å·²åˆ›å»ºCSVæ–‡ä»¶ {filename}")
    
    # 2. è¯»å–CSVæ–‡ä»¶
    print("\n2. è¯»å–CSVæ–‡ä»¶")
    with open(filename, 'r', encoding='utf-8') as f:
        reader = csv.reader(f)
        for row_num, row in enumerate(reader):
            print(f"ç¬¬{row_num + 1}è¡Œ: {row}")
    
    # 3. è®¡ç®—å¹³å‡å¹´é¾„
    print("\n3. è®¡ç®—å¹³å‡å¹´é¾„")
    with open(filename, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        ages = [int(row['å¹´é¾„']) for row in reader]
    
    average_age = sum(ages) / len(ages)
    print(f"å¹³å‡å¹´é¾„: {average_age:.1f}å²")
    
    # 4. æŒ‰åŸå¸‚åˆ†ç»„
    print("\n4. æŒ‰åŸå¸‚åˆ†ç»„")
    with open(filename, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        city_groups = defaultdict(list)
        for row in reader:
            city_groups[row['åŸå¸‚']].append(row['å§“å'])
    
    for city, names in city_groups.items():
        print(f"{city}: {', '.join(names)}")
    
    # 5. æŒ‰å¹´é¾„æ’åºå¹¶å†™å…¥æ–°æ–‡ä»¶
    print("\n5. æŒ‰å¹´é¾„æ’åº")
    with open(filename, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        sorted_employees = sorted(reader, key=lambda x: int(x['å¹´é¾„']))
    
    sorted_filename = 'employees_sorted.csv'
    with open(sorted_filename, 'w', newline='', encoding='utf-8') as f:
        fieldnames = ['å§“å', 'å¹´é¾„', 'åŸå¸‚', 'èŒä¸š']
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(sorted_employees)
    
    print(f"å·²åˆ›å»ºæŒ‰å¹´é¾„æ’åºçš„æ–‡ä»¶ {sorted_filename}")
    
    # æ˜¾ç¤ºæ’åºç»“æœ
    with open(sorted_filename, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            print(f"{row['å§“å']}: {row['å¹´é¾„']}å²")
    
    # æ¸…ç†
    os.remove(filename)
    os.remove(sorted_filename)
    print("å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶")

csv_processor_demo()

# ç»ƒä¹  2.2: JSONæ–‡ä»¶å¤„ç†
print("\n\nç»ƒä¹  2.2: JSONæ–‡ä»¶å¤„ç†")

def json_processor_demo():
    """JSONæ–‡ä»¶å¤„ç†æ¼”ç¤º"""
    filename = 'school_data.json'
    
    # 1. åˆ›å»ºå¤æ‚çš„æ•°æ®ç»“æ„
    print("1. åˆ›å»ºå­¦æ ¡æ•°æ®")
    school_data = {
        "school_info": {
            "name": "åŒ—äº¬ç†å·¥å¤§å­¦",
            "address": "åŒ—äº¬å¸‚æµ·æ·€åŒºä¸­å…³æ‘å—å¤§è¡—5å·",
            "founded_year": 1940
        },
        "courses": [
            {
                "course_name": "Pythonç¼–ç¨‹",
                "teacher": "å¼ æ•™æˆ",
                "credits": 3
            },
            {
                "course_name": "æ•°æ®ç»“æ„",
                "teacher": "ææ•™æˆ",
                "credits": 4
            },
            {
                "course_name": "ç®—æ³•è®¾è®¡",
                "teacher": "ç‹æ•™æˆ",
                "credits": 3
            }
        ],
        "students": [
            {
                "id": 1,
                "name": "å¼ ä¸‰",
                "age": 20,
                "grades": [85, 92, 78, 88, 95]
            },
            {
                "id": 2,
                "name": "æå››",
                "age": 21,
                "grades": [90, 87, 93, 89, 91]
            },
            {
                "id": 3,
                "name": "ç‹äº”",
                "age": 19,
                "grades": [78, 85, 82, 79, 88]
            },
            {
                "id": 4,
                "name": "èµµå…­",
                "age": 22,
                "grades": [95, 98, 92, 96, 94]
            }
        ]
    }
    
    # 2. ä¿å­˜ä¸ºJSONæ–‡ä»¶
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(school_data, f, ensure_ascii=False, indent=2)
    print(f"å·²åˆ›å»ºJSONæ–‡ä»¶ {filename}")
    
    # 3. ä»JSONæ–‡ä»¶è¯»å–æ•°æ®
    print("\n2. è¯»å–JSONæ•°æ®")
    with open(filename, 'r', encoding='utf-8') as f:
        loaded_data = json.load(f)
    
    print(f"å­¦æ ¡: {loaded_data['school_info']['name']}")
    print(f"å»ºæ ¡å¹´ä»½: {loaded_data['school_info']['founded_year']}")
    print(f"è¯¾ç¨‹æ•°é‡: {len(loaded_data['courses'])}")
    print(f"å­¦ç”Ÿæ•°é‡: {len(loaded_data['students'])}")
    
    # 4. è®¡ç®—æ¯ä¸ªå­¦ç”Ÿçš„å¹³å‡æˆç»©
    print("\n3. è®¡ç®—å­¦ç”Ÿå¹³å‡æˆç»©")
    for student in loaded_data['students']:
        avg_grade = sum(student['grades']) / len(student['grades'])
        student['average_grade'] = round(avg_grade, 2)
        print(f"{student['name']}: {avg_grade:.2f}")
    
    # 5. æ‰¾å‡ºå¹³å‡æˆç»©æœ€é«˜çš„å­¦ç”Ÿ
    print("\n4. æ‰¾å‡ºå¹³å‡æˆç»©æœ€é«˜çš„å­¦ç”Ÿ")
    best_student = max(loaded_data['students'], key=lambda x: x['average_grade'])
    print(f"æœ€é«˜å¹³å‡åˆ†å­¦ç”Ÿ: {best_student['name']} ({best_student['average_grade']}åˆ†)")
    
    # 6. ä¿®æ”¹å­¦ç”Ÿä¿¡æ¯
    print("\n5. ä¿®æ”¹å­¦ç”Ÿä¿¡æ¯")
    # ä¸ºå¼ ä¸‰æ·»åŠ ä¸€é—¨æ–°æˆç»©
    for student in loaded_data['students']:
        if student['name'] == 'å¼ ä¸‰':
            student['grades'].append(96)
            student['average_grade'] = sum(student['grades']) / len(student['grades'])
            print(f"å·²ä¸º{student['name']}æ·»åŠ æ–°æˆç»©ï¼Œæ–°å¹³å‡åˆ†: {student['average_grade']:.2f}")
            break
    
    # 7. ä¿å­˜ä¿®æ”¹åçš„æ•°æ®
    updated_filename = 'school_data_updated.json'
    with open(updated_filename, 'w', encoding='utf-8') as f:
        json.dump(loaded_data, f, ensure_ascii=False, indent=2)
    print(f"å·²ä¿å­˜ä¿®æ”¹åçš„æ•°æ®åˆ° {updated_filename}")
    
    # æ¸…ç†
    os.remove(filename)
    os.remove(updated_filename)
    print("å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶")

json_processor_demo()

# ç»ƒä¹  2.3: æ–‡æœ¬æ–‡ä»¶åˆ†æå™¨
print("\n\nç»ƒä¹  2.3: æ–‡æœ¬æ–‡ä»¶åˆ†æå™¨")

class TextAnalyzer:
    """æ–‡æœ¬åˆ†æå™¨ç±»"""
    
    def __init__(self, filename: str):
        self.filename = filename
        self.stats = {
            'total_chars': 0,
            'total_chars_no_spaces': 0,
            'total_words': 0,
            'total_lines': 0,
            'avg_chars_per_line': 0,
            'avg_words_per_line': 0,
            'most_common_words': [],
            'longest_sentence': '',
            'punctuation_count': {}
        }
    
    def analyze(self) -> dict:
        """åˆ†ææ–‡æœ¬æ–‡ä»¶"""
        try:
            with open(self.filename, 'r', encoding='utf-8') as f:
                content = f.read()
            
            self._analyze_content(content)
            return self.stats
            
        except Exception as e:
            raise Exception(f"åˆ†ææ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    def _analyze_content(self, content: str):
        """åˆ†ææ–‡æœ¬å†…å®¹"""
        lines = content.split('\n')
        words = re.findall(r'\b\w+\b', content.lower())
        sentences = re.split(r'[.!?]+', content)
        
        # åŸºæœ¬ç»Ÿè®¡
        self.stats['total_chars'] = len(content)
        self.stats['total_chars_no_spaces'] = len(content.replace(' ', ''))
        self.stats['total_words'] = len(words)
        self.stats['total_lines'] = len(lines)
        
        # å¹³å‡å€¼
        if self.stats['total_lines'] > 0:
            self.stats['avg_chars_per_line'] = self.stats['total_chars'] / self.stats['total_lines']
            self.stats['avg_words_per_line'] = self.stats['total_words'] / self.stats['total_lines']
        
        # æœ€å¸¸è§çš„å•è¯
        word_counter = Counter(words)
        self.stats['most_common_words'] = word_counter.most_common(10)
        
        # æœ€é•¿çš„å¥å­
        if sentences:
            self.stats['longest_sentence'] = max(sentences, key=len).strip()
        
        # æ ‡ç‚¹ç¬¦å·ç»Ÿè®¡
        punctuation = '.,;:!?"()[]{}'
        for char in content:
            if char in punctuation:
                self.stats['punctuation_count'][char] = self.stats['punctuation_count'].get(char, 0) + 1
    
    def save_report(self, report_filename: str):
        """ä¿å­˜åˆ†ææŠ¥å‘Š"""
        with open(report_filename, 'w', encoding='utf-8') as f:
            f.write(f"æ–‡æœ¬åˆ†ææŠ¥å‘Š\n")
            f.write(f"=" * 30 + "\n\n")
            f.write(f"æ–‡ä»¶å: {self.filename}\n")
            f.write(f"åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write(f"åŸºæœ¬ç»Ÿè®¡:\n")
            f.write(f"  æ€»å­—ç¬¦æ•°: {self.stats['total_chars']}\n")
            f.write(f"  æ€»å­—ç¬¦æ•°(ä¸å«ç©ºæ ¼): {self.stats['total_chars_no_spaces']}\n")
            f.write(f"  æ€»å•è¯æ•°: {self.stats['total_words']}\n")
            f.write(f"  æ€»è¡Œæ•°: {self.stats['total_lines']}\n")
            f.write(f"  å¹³å‡æ¯è¡Œå­—ç¬¦æ•°: {self.stats['avg_chars_per_line']:.2f}\n")
            f.write(f"  å¹³å‡æ¯è¡Œå•è¯æ•°: {self.stats['avg_words_per_line']:.2f}\n\n")
            
            f.write(f"æœ€å¸¸è§çš„10ä¸ªå•è¯:\n")
            for word, count in self.stats['most_common_words']:
                f.write(f"  {word}: {count}æ¬¡\n")
            
            f.write(f"\næœ€é•¿çš„å¥å­:\n")
            f.write(f"  {self.stats['longest_sentence'][:100]}...\n")
            
            f.write(f"\næ ‡ç‚¹ç¬¦å·ç»Ÿè®¡:\n")
            for punct, count in sorted(self.stats['punctuation_count'].items()):
                f.write(f"  '{punct}': {count}æ¬¡\n")

def text_analyzer_demo():
    """æ–‡æœ¬åˆ†æå™¨æ¼”ç¤º"""
    # åˆ›å»ºç¤ºä¾‹æ–‡æœ¬æ–‡ä»¶
    sample_text = """è¿™æ˜¯ä¸€ä¸ªç¤ºä¾‹æ–‡æœ¬æ–‡ä»¶ï¼Œç”¨äºæ¼”ç¤ºæ–‡æœ¬åˆ†æå™¨çš„åŠŸèƒ½ã€‚
æ–‡æœ¬åˆ†ææ˜¯è‡ªç„¶è¯­è¨€å¤„ç†çš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚
é€šè¿‡åˆ†ææ–‡æœ¬ï¼Œæˆ‘ä»¬å¯ä»¥äº†è§£æ–‡æœ¬çš„åŸºæœ¬ç‰¹å¾ï¼Œå¦‚å­—ç¬¦æ•°ã€å•è¯æ•°ã€å¥å­æ•°ç­‰ã€‚
è¿™ä¸ªåˆ†æå™¨è¿˜å¯ä»¥ç»Ÿè®¡æœ€å¸¸è§çš„å•è¯å’Œæ ‡ç‚¹ç¬¦å·çš„ä½¿ç”¨æƒ…å†µã€‚

Pythonæ˜¯ä¸€ç§å¼ºå¤§çš„ç¼–ç¨‹è¯­è¨€ï¼Œç‰¹åˆ«é€‚åˆæ–‡æœ¬å¤„ç†å’Œæ•°æ®åˆ†æã€‚
ä½¿ç”¨Pythonï¼Œæˆ‘ä»¬å¯ä»¥è½»æ¾åœ°è¯»å–æ–‡ä»¶ã€å¤„ç†å­—ç¬¦ä¸²ã€ç»Ÿè®¡æ•°æ®ã€‚
æ­£åˆ™è¡¨è¾¾å¼æ˜¯æ–‡æœ¬å¤„ç†ä¸­çš„åˆ©å™¨ï¼Œå¯ä»¥å¸®åŠ©æˆ‘ä»¬æå–å’ŒåŒ¹é…ç‰¹å®šçš„æ¨¡å¼ã€‚

è¿™ä¸ªç¤ºä¾‹åŒ…å«äº†ä¸­æ–‡å’Œè‹±æ–‡å†…å®¹ï¼Œä»¥åŠå„ç§æ ‡ç‚¹ç¬¦å·ï¼š,.;:!?"()[]{}ã€‚
é€šè¿‡åˆ†æè¿™äº›å†…å®¹ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°æœ‰ç”¨çš„ç»Ÿè®¡ä¿¡æ¯ã€‚
"""
    
    test_filename = 'sample_text.txt'
    with open(test_filename, 'w', encoding='utf-8') as f:
        f.write(sample_text)
    
    print("æ–‡æœ¬åˆ†æå™¨æ¼”ç¤º")
    
    # åˆ›å»ºåˆ†æå™¨å¹¶åˆ†ææ–‡ä»¶
    analyzer = TextAnalyzer(test_filename)
    stats = analyzer.analyze()
    
    # æ˜¾ç¤ºåˆ†æç»“æœ
    print(f"\nåˆ†æç»“æœ:")
    print(f"  æ€»å­—ç¬¦æ•°: {stats['total_chars']}")
    print(f"  æ€»å­—ç¬¦æ•°(ä¸å«ç©ºæ ¼): {stats['total_chars_no_spaces']}")
    print(f"  æ€»å•è¯æ•°: {stats['total_words']}")
    print(f"  æ€»è¡Œæ•°: {stats['total_lines']}")
    print(f"  å¹³å‡æ¯è¡Œå­—ç¬¦æ•°: {stats['avg_chars_per_line']:.2f}")
    print(f"  å¹³å‡æ¯è¡Œå•è¯æ•°: {stats['avg_words_per_line']:.2f}")
    
    print(f"\næœ€å¸¸è§çš„5ä¸ªå•è¯:")
    for word, count in stats['most_common_words'][:5]:
        print(f"  {word}: {count}æ¬¡")
    
    print(f"\næœ€é•¿çš„å¥å­: {stats['longest_sentence'][:50]}...")
    
    print(f"\næ ‡ç‚¹ç¬¦å·ç»Ÿè®¡:")
    for punct, count in list(stats['punctuation_count'].items())[:5]:
        print(f"  '{punct}': {count}æ¬¡")
    
    # ä¿å­˜æŠ¥å‘Š
    report_filename = 'text_analysis_report.txt'
    analyzer.save_report(report_filename)
    print(f"\nåˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ° {report_filename}")
    
    # æ¸…ç†
    os.remove(test_filename)
    os.remove(report_filename)
    print("å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶")

text_analyzer_demo()

# ============================================================================
# 3. äºŒè¿›åˆ¶æ–‡ä»¶å¤„ç†ç»ƒä¹ ç­”æ¡ˆ
# ============================================================================

print("\n\n3. äºŒè¿›åˆ¶æ–‡ä»¶å¤„ç†ç»ƒä¹ ç­”æ¡ˆ")
print("-" * 30)

# ç»ƒä¹  3.1: å›¾åƒæ–‡ä»¶å…ƒæ•°æ®è¯»å–å™¨
print("\nç»ƒä¹  3.1: å›¾åƒæ–‡ä»¶å…ƒæ•°æ®è¯»å–å™¨")

class ImageMetadataReader:
    """å›¾åƒæ–‡ä»¶å…ƒæ•°æ®è¯»å–å™¨"""
    
    def __init__(self, image_path: str):
        self.image_path = image_path
        self.metadata = {}
    
    def read_metadata(self) -> dict:
        """è¯»å–å›¾åƒå…ƒæ•°æ®"""
        try:
            # åŸºæœ¬æ–‡ä»¶ä¿¡æ¯
            file_stat = os.stat(self.image_path)
            self.metadata['file_size'] = file_stat.st_size
            self.metadata['created_time'] = datetime.fromtimestamp(file_stat.st_ctime)
            self.metadata['modified_time'] = datetime.fromtimestamp(file_stat.st_mtime)
            
            # å°è¯•è¯»å–å›¾åƒä¿¡æ¯ï¼ˆç®€åŒ–ç‰ˆï¼Œä¸ä½¿ç”¨PILï¼‰
            self._read_basic_image_info()
            
            return self.metadata
            
        except Exception as e:
            raise Exception(f"è¯»å–å›¾åƒå…ƒæ•°æ®å¤±è´¥: {e}")
    
    def _read_basic_image_info(self):
        """è¯»å–åŸºæœ¬å›¾åƒä¿¡æ¯ï¼ˆç®€åŒ–å®ç°ï¼‰"""
        with open(self.image_path, 'rb') as f:
            # è¯»å–æ–‡ä»¶å¤´
            header = f.read(20)
            
            # æ£€æµ‹æ–‡ä»¶æ ¼å¼
            if header.startswith(b'\xff\xd8\xff'):
                self.metadata['format'] = 'JPEG'
                self._read_jpeg_info(f)
            elif header.startswith(b'\x89PNG\r\n\x1a\n'):
                self.metadata['format'] = 'PNG'
                self._read_png_info(f)
            elif header.startswith(b'GIF87a') or header.startswith(b'GIF89a'):
                self.metadata['format'] = 'GIF'
                self._read_gif_info(f)
            else:
                self.metadata['format'] = 'Unknown'
                self.metadata['width'] = 'Unknown'
                self.metadata['height'] = 'Unknown'
    
    def _read_jpeg_info(self, f):
        """è¯»å–JPEGä¿¡æ¯ï¼ˆç®€åŒ–å®ç°ï¼‰"""
        # è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„JPEGè§£æï¼Œå®é™…åº”ç”¨ä¸­å»ºè®®ä½¿ç”¨PIL
        self.metadata['width'] = 'Unknown (éœ€è¦PILåº“)'
        self.metadata['height'] = 'Unknown (éœ€è¦PILåº“)'
        self.metadata['color_depth'] = 'Unknown (éœ€è¦PILåº“)'
    
    def _read_png_info(self, f):
        """è¯»å–PNGä¿¡æ¯ï¼ˆç®€åŒ–å®ç°ï¼‰"""
        f.seek(16)  # è·³åˆ°IHDRå—
        width_bytes = f.read(4)
        height_bytes = f.read(4)
        
        if len(width_bytes) == 4 and len(height_bytes) == 4:
            self.metadata['width'] = int.from_bytes(width_bytes, 'big')
            self.metadata['height'] = int.from_bytes(height_bytes, 'big')
        else:
            self.metadata['width'] = 'Unknown'
            self.metadata['height'] = 'Unknown'
        
        self.metadata['color_depth'] = 'Unknown (éœ€è¦è¯¦ç»†è§£æ)'
    
    def _read_gif_info(self, f):
        """è¯»å–GIFä¿¡æ¯ï¼ˆç®€åŒ–å®ç°ï¼‰"""
        f.seek(6)  # è·³åˆ°å°ºå¯¸ä¿¡æ¯
        width_bytes = f.read(2)
        height_bytes = f.read(2)
        
        if len(width_bytes) == 2 and len(height_bytes) == 2:
            self.metadata['width'] = int.from_bytes(width_bytes, 'little')
            self.metadata['height'] = int.from_bytes(height_bytes, 'little')
        else:
            self.metadata['width'] = 'Unknown'
            self.metadata['height'] = 'Unknown'
        
        self.metadata['color_depth'] = 'Unknown (éœ€è¦è¯¦ç»†è§£æ)'

def create_sample_image():
    """åˆ›å»ºä¸€ä¸ªç®€å•çš„PNGå›¾åƒæ–‡ä»¶ç”¨äºæµ‹è¯•"""
    # åˆ›å»ºä¸€ä¸ªæœ€å°çš„PNGæ–‡ä»¶ï¼ˆ1x1åƒç´ ï¼Œç™½è‰²ï¼‰
    png_data = (
        b'\x89PNG\r\n\x1a\n'  # PNGç­¾å
        b'\x00\x00\x00\rIHDR'  # IHDRå—å¤´
        b'\x00\x00\x00\x01'    # å®½åº¦ï¼š1
        b'\x00\x00\x00\x01'    # é«˜åº¦ï¼š1
        b'\x08\x02\x00\x00\x00'  # ä½æ·±åº¦ã€é¢œè‰²ç±»å‹ç­‰
        b'\x90wS\xde'         # CRC
        b'\x00\x00\x00\nIDAT'  # IDATå—å¤´
        b'x\x9cc```\x00\x00\x00\x02\x00\x01'  # å‹ç¼©çš„å›¾åƒæ•°æ®
        b'\xe2!\xbc3'         # CRC
        b'\x00\x00\x00\x00IEND'  # IENDå—å¤´
        b'\xaeB`\x82'         # CRC
    )
    
    with open('sample_image.png', 'wb') as f:
        f.write(png_data)
    
    return 'sample_image.png'

def image_metadata_demo():
    """å›¾åƒå…ƒæ•°æ®è¯»å–å™¨æ¼”ç¤º"""
    print("å›¾åƒå…ƒæ•°æ®è¯»å–å™¨æ¼”ç¤º")
    
    # åˆ›å»ºç¤ºä¾‹å›¾åƒ
    image_file = create_sample_image()
    print(f"å·²åˆ›å»ºç¤ºä¾‹å›¾åƒ: {image_file}")
    
    # è¯»å–å…ƒæ•°æ®
    reader = ImageMetadataReader(image_file)
    metadata = reader.read_metadata()
    
    print(f"\nå›¾åƒå…ƒæ•°æ®:")
    for key, value in metadata.items():
        print(f"  {key}: {value}")
    
    # æ¸…ç†
    os.remove(image_file)
    print(f"å·²åˆ é™¤ç¤ºä¾‹å›¾åƒ")

image_metadata_demo()

# ç»ƒä¹  3.2: ç®€å•æ–‡ä»¶åŠ å¯†è§£å¯†å™¨
print("\n\nç»ƒä¹  3.2: ç®€å•æ–‡ä»¶åŠ å¯†è§£å¯†å™¨")

class SimpleFileEncryptor:
    """ç®€å•æ–‡ä»¶åŠ å¯†è§£å¯†å™¨"""
    
    @staticmethod
    def encrypt_file(input_file: str, output_file: str, key: str) -> bool:
        """åŠ å¯†æ–‡ä»¶
        
        Args:
            input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            key: åŠ å¯†å¯†é’¥
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            with open(input_file, 'rb') as infile, open(output_file, 'wb') as outfile:
                key_bytes = key.encode('utf-8')
                key_len = len(key_bytes)
                
                while True:
                    chunk = infile.read(8192)  # 8KBå—
                    if not chunk:
                        break
                    
                    # ä½¿ç”¨XORåŠ å¯†
                    encrypted_chunk = bytearray()
                    for i, byte in enumerate(chunk):
                        encrypted_byte = byte ^ key_bytes[i % key_len]
                        encrypted_chunk.append(encrypted_byte)
                    
                    outfile.write(encrypted_chunk)
            
            return True
            
        except Exception as e:
            print(f"åŠ å¯†å¤±è´¥: {e}")
            return False
    
    @staticmethod
    def decrypt_file(input_file: str, output_file: str, key: str) -> bool:
        """è§£å¯†æ–‡ä»¶
        
        Args:
            input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            key: è§£å¯†å¯†é’¥
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        # XORåŠ å¯†çš„ç‰¹æ€§ï¼šåŠ å¯†å’Œè§£å¯†ä½¿ç”¨ç›¸åŒçš„æ“ä½œ
        return SimpleFileEncryptor.encrypt_file(input_file, output_file, key)
    
    @staticmethod
    def verify_files_identical(file1: str, file2: str) -> bool:
        """éªŒè¯ä¸¤ä¸ªæ–‡ä»¶æ˜¯å¦ç›¸åŒ"""
        try:
            with open(file1, 'rb') as f1, open(file2, 'rb') as f2:
                while True:
                    chunk1 = f1.read(8192)
                    chunk2 = f2.read(8192)
                    
                    if chunk1 != chunk2:
                        return False
                    
                    if not chunk1:  # ä¸¤ä¸ªæ–‡ä»¶éƒ½åˆ°è¾¾æœ«å°¾
                        return True
                        
        except Exception:
            return False

def file_encryption_demo():
    """æ–‡ä»¶åŠ å¯†è§£å¯†æ¼”ç¤º"""
    print("æ–‡ä»¶åŠ å¯†è§£å¯†æ¼”ç¤º")
    
    # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
    original_file = 'original.txt'
    encrypted_file = 'encrypted.bin'
    decrypted_file = 'decrypted.txt'
    
    test_content = """è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡ä»¶ï¼Œç”¨äºæ¼”ç¤ºæ–‡ä»¶åŠ å¯†å’Œè§£å¯†åŠŸèƒ½ã€‚
æ–‡ä»¶åŒ…å«ä¸­æ–‡å’Œè‹±æ–‡å†…å®¹ã€‚
This file contains both Chinese and English content.
åŠ å¯†ç®—æ³•ä½¿ç”¨ç®€å•çš„XORæ“ä½œã€‚
The encryption algorithm uses simple XOR operation.
æµ‹è¯•æ•°æ®ï¼š1234567890
Test data: abcdefghijklmnopqrstuvwxyz
"""
    
    with open(original_file, 'w', encoding='utf-8') as f:
        f.write(test_content)
    
    print(f"å·²åˆ›å»ºåŸå§‹æ–‡ä»¶: {original_file}")
    
    # åŠ å¯†æ–‡ä»¶
    encryption_key = "MySecretKey123"
    success = SimpleFileEncryptor.encrypt_file(original_file, encrypted_file, encryption_key)
    
    if success:
        print(f"æ–‡ä»¶åŠ å¯†æˆåŠŸ: {encrypted_file}")
        
        # æ˜¾ç¤ºåŠ å¯†æ–‡ä»¶çš„å‰å‡ ä¸ªå­—èŠ‚
        with open(encrypted_file, 'rb') as f:
            encrypted_data = f.read(50)
        print(f"åŠ å¯†æ•°æ®é¢„è§ˆ: {encrypted_data.hex()}")
        
        # è§£å¯†æ–‡ä»¶
        success = SimpleFileEncryptor.decrypt_file(encrypted_file, decrypted_file, encryption_key)
        
        if success:
            print(f"æ–‡ä»¶è§£å¯†æˆåŠŸ: {decrypted_file}")
            
            # éªŒè¯è§£å¯†åçš„æ–‡ä»¶ä¸åŸå§‹æ–‡ä»¶æ˜¯å¦ç›¸åŒ
            if SimpleFileEncryptor.verify_files_identical(original_file, decrypted_file):
                print("âœ“ éªŒè¯æˆåŠŸï¼šè§£å¯†åçš„æ–‡ä»¶ä¸åŸå§‹æ–‡ä»¶å®Œå…¨ç›¸åŒ")
            else:
                print("âœ— éªŒè¯å¤±è´¥ï¼šè§£å¯†åçš„æ–‡ä»¶ä¸åŸå§‹æ–‡ä»¶ä¸åŒ")
            
            # æ˜¾ç¤ºè§£å¯†åçš„å†…å®¹
            with open(decrypted_file, 'r', encoding='utf-8') as f:
                decrypted_content = f.read(100)
            print(f"è§£å¯†å†…å®¹é¢„è§ˆ: {decrypted_content[:100]}...")
        
        else:
            print("æ–‡ä»¶è§£å¯†å¤±è´¥")
    else:
        print("æ–‡ä»¶åŠ å¯†å¤±è´¥")
    
    # æµ‹è¯•é”™è¯¯çš„å¯†é’¥
    print("\næµ‹è¯•é”™è¯¯å¯†é’¥:")
    wrong_key_file = 'wrong_key_decrypted.txt'
    SimpleFileEncryptor.decrypt_file(encrypted_file, wrong_key_file, "WrongKey")
    
    try:
        with open(wrong_key_file, 'r', encoding='utf-8', errors='ignore') as f:
            wrong_content = f.read(50)
        print(f"é”™è¯¯å¯†é’¥è§£å¯†ç»“æœ: {repr(wrong_content)}")
    except:
        print("é”™è¯¯å¯†é’¥è§£å¯†ç»“æœæ— æ³•è¯»å–ï¼ˆä¹±ç ï¼‰")
    
    # æ¸…ç†
    for filename in [original_file, encrypted_file, decrypted_file, wrong_key_file]:
        if os.path.exists(filename):
            os.remove(filename)
    print("å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶")

file_encryption_demo()

# ç»ƒä¹  3.3: å¯¹è±¡åºåˆ—åŒ–ä¸ååºåˆ—åŒ–
print("\n\nç»ƒä¹  3.3: å¯¹è±¡åºåˆ—åŒ–ä¸ååºåˆ—åŒ–")

class Student:
    """å­¦ç”Ÿç±»"""
    
    def __init__(self, student_id: int, name: str, age: int):
        self.student_id = student_id
        self.name = name
        self.age = age
        self.courses = []
        self.grades = {}
    
    def add_course(self, course_name: str):
        """æ·»åŠ è¯¾ç¨‹"""
        if course_name not in self.courses:
            self.courses.append(course_name)
    
    def add_grade(self, course_name: str, grade: float):
        """æ·»åŠ æˆç»©"""
        self.grades[course_name] = grade
    
    def calculate_average(self) -> float:
        """è®¡ç®—å¹³å‡åˆ†"""
        if not self.grades:
            return 0.0
        return sum(self.grades.values()) / len(self.grades)
    
    def display_info(self) -> str:
        """æ˜¾ç¤ºå­¦ç”Ÿä¿¡æ¯"""
        avg_grade = self.calculate_average()
        return f"å­¦ç”ŸID: {self.student_id}, å§“å: {self.name}, å¹´é¾„: {self.age}, å¹³å‡åˆ†: {avg_grade:.2f}"
    
    def to_dict(self) -> dict:
        """è½¬æ¢ä¸ºå­—å…¸ï¼ˆç”¨äºJSONåºåˆ—åŒ–ï¼‰"""
        return {
            'student_id': self.student_id,
            'name': self.name,
            'age': self.age,
            'courses': self.courses,
            'grades': self.grades
        }
    
    @classmethod
    def from_dict(cls, data: dict) -> 'Student':
        """ä»å­—å…¸åˆ›å»ºå­¦ç”Ÿå¯¹è±¡"""
        student = cls(data['student_id'], data['name'], data['age'])
        student.courses = data.get('courses', [])
        student.grades = data.get('grades', {})
        return student
    
    def __repr__(self):
        return f"Student({self.student_id}, '{self.name}', {self.age})"

class ObjectSerializer:
    """å¯¹è±¡åºåˆ—åŒ–å™¨"""
    
    @staticmethod
    def serialize_with_pickle(objects: list, filename: str) -> bool:
        """ä½¿ç”¨pickleåºåˆ—åŒ–å¯¹è±¡"""
        try:
            with open(filename, 'wb') as f:
                pickle.dump(objects, f)
            return True
        except Exception as e:
            print(f"Pickleåºåˆ—åŒ–å¤±è´¥: {e}")
            return False
    
    @staticmethod
    def deserialize_with_pickle(filename: str) -> list:
        """ä½¿ç”¨pickleååºåˆ—åŒ–å¯¹è±¡"""
        try:
            with open(filename, 'rb') as f:
                return pickle.load(f)
        except Exception as e:
            print(f"Pickleååºåˆ—åŒ–å¤±è´¥: {e}")
            return []
    
    @staticmethod
    def serialize_with_json(objects: list, filename: str) -> bool:
        """ä½¿ç”¨JSONåºåˆ—åŒ–å¯¹è±¡"""
        try:
            # è½¬æ¢å¯¹è±¡ä¸ºå­—å…¸
            data = [obj.to_dict() if hasattr(obj, 'to_dict') else obj for obj in objects]
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            return True
        except Exception as e:
            print(f"JSONåºåˆ—åŒ–å¤±è´¥: {e}")
            return False
    
    @staticmethod
    def deserialize_with_json(filename: str, object_class=None) -> list:
        """ä½¿ç”¨JSONååºåˆ—åŒ–å¯¹è±¡"""
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # å¦‚æœæä¾›äº†å¯¹è±¡ç±»ï¼Œå°è¯•é‡å»ºå¯¹è±¡
            if object_class and hasattr(object_class, 'from_dict'):
                return [object_class.from_dict(item) for item in data]
            else:
                return data
                
        except Exception as e:
            print(f"JSONååºåˆ—åŒ–å¤±è´¥: {e}")
            return []

def object_serialization_demo():
    """å¯¹è±¡åºåˆ—åŒ–æ¼”ç¤º"""
    print("å¯¹è±¡åºåˆ—åŒ–ä¸ååºåˆ—åŒ–æ¼”ç¤º")
    
    # åˆ›å»ºå­¦ç”Ÿå¯¹è±¡
    students = [
        Student(1, "å¼ ä¸‰", 20),
        Student(2, "æå››", 21),
        Student(3, "ç‹äº”", 19),
        Student(4, "èµµå…­", 22)
    ]
    
    # æ·»åŠ è¯¾ç¨‹å’Œæˆç»©
    courses = ["Pythonç¼–ç¨‹", "æ•°æ®ç»“æ„", "ç®—æ³•è®¾è®¡", "æ•°æ®åº“åŸç†"]
    
    for student in students:
        for course in courses:
            student.add_course(course)
            # éšæœºç”Ÿæˆæˆç»©
            import random
            grade = random.uniform(75, 95)
            student.add_grade(course, grade)
    
    print(f"åˆ›å»ºäº†{len(students)}ä¸ªå­¦ç”Ÿå¯¹è±¡")
    for student in students:
        print(f"  {student.display_info()}")
    
    # Pickleåºåˆ—åŒ–
    print("\n1. Pickleåºåˆ—åŒ–æµ‹è¯•")
    pickle_file = 'students.pickle'
    
    if ObjectSerializer.serialize_with_pickle(students, pickle_file):
        print(f"Pickleåºåˆ—åŒ–æˆåŠŸ: {pickle_file}")
        
        # ååºåˆ—åŒ–
        loaded_students = ObjectSerializer.deserialize_with_pickle(pickle_file)
        print(f"Pickleååºåˆ—åŒ–æˆåŠŸï¼ŒåŠ è½½äº†{len(loaded_students)}ä¸ªå¯¹è±¡")
        
        # éªŒè¯å¯¹è±¡å®Œæ•´æ€§
        if loaded_students and hasattr(loaded_students[0], 'display_info'):
            print(f"ç¬¬ä¸€ä¸ªå­¦ç”Ÿä¿¡æ¯: {loaded_students[0].display_info()}")
        
        # æ–‡ä»¶å¤§å°
        file_size = os.path.getsize(pickle_file)
        print(f"Pickleæ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚")
    
    # JSONåºåˆ—åŒ–
    print("\n2. JSONåºåˆ—åŒ–æµ‹è¯•")
    json_file = 'students.json'
    
    if ObjectSerializer.serialize_with_json(students, json_file):
        print(f"JSONåºåˆ—åŒ–æˆåŠŸ: {json_file}")
        
        # ååºåˆ—åŒ–
        loaded_data = ObjectSerializer.deserialize_with_json(json_file, Student)
        print(f"JSONååºåˆ—åŒ–æˆåŠŸï¼ŒåŠ è½½äº†{len(loaded_data)}ä¸ªå¯¹è±¡")
        
        # éªŒè¯å¯¹è±¡å®Œæ•´æ€§
        if loaded_data and hasattr(loaded_data[0], 'display_info'):
            print(f"ç¬¬ä¸€ä¸ªå­¦ç”Ÿä¿¡æ¯: {loaded_data[0].display_info()}")
        
        # æ–‡ä»¶å¤§å°
        file_size = os.path.getsize(json_file)
        print(f"JSONæ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚")
    
    # æ¯”è¾ƒä¸¤ç§æ–¹æ³•
    print("\n3. åºåˆ—åŒ–æ–¹æ³•æ¯”è¾ƒ")
    print("Pickleä¼˜ç‚¹:")
    print("  - å¯ä»¥åºåˆ—åŒ–å‡ ä¹æ‰€æœ‰Pythonå¯¹è±¡")
    print("  - ä¿æŒå¯¹è±¡çš„å®Œæ•´æ€§ï¼ˆåŒ…æ‹¬æ–¹æ³•ï¼‰")
    print("  - æ–‡ä»¶é€šå¸¸æ›´å°")
    print("Pickleç¼ºç‚¹:")
    print("  - åªèƒ½åœ¨Pythonä¸­ä½¿ç”¨")
    print("  - å­˜åœ¨å®‰å…¨é£é™©ï¼ˆä¸è¦åŠ è½½ä¸ä¿¡ä»»çš„pickleæ–‡ä»¶ï¼‰")
    print("  - ä¸å¯è¯»")
    
    print("\nJSONä¼˜ç‚¹:")
    print("  - è·¨è¯­è¨€å…¼å®¹")
    print("  - äººç±»å¯è¯»")
    print("  - å®‰å…¨")
    print("JSONç¼ºç‚¹:")
    print("  - åªèƒ½åºåˆ—åŒ–åŸºæœ¬æ•°æ®ç±»å‹")
    print("  - éœ€è¦è‡ªå®šä¹‰è½¬æ¢æ–¹æ³•")
    print("  - ä¸ä¿æŒå¯¹è±¡æ–¹æ³•")
    
    # æ¸…ç†
    for filename in [pickle_file, json_file]:
        if os.path.exists(filename):
            os.remove(filename)
    print("\nå·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶")

object_serialization_demo()

# ============================================================================
# 4. æ–‡ä»¶ç³»ç»Ÿæ“ä½œç»ƒä¹ ç­”æ¡ˆ
# ============================================================================

print("\n\n4. æ–‡ä»¶ç³»ç»Ÿæ“ä½œç»ƒä¹ ç­”æ¡ˆ")
print("-" * 30)

# ç»ƒä¹  4.1: æ–‡ä»¶ç³»ç»Ÿæµè§ˆå™¨
print("\nç»ƒä¹  4.1: æ–‡ä»¶ç³»ç»Ÿæµè§ˆå™¨")

class FileExplorer:
    """ç®€å•çš„æ–‡ä»¶ç³»ç»Ÿæµè§ˆå™¨"""
    
    def __init__(self, start_dir: str = '.'):
        self.current_dir = Path(start_dir).resolve()
        self.running = True
    
    def run(self):
        """è¿è¡Œæ–‡ä»¶æµè§ˆå™¨"""
        print("æ–‡ä»¶ç³»ç»Ÿæµè§ˆå™¨")
        print("å‘½ä»¤: ls(åˆ—å‡º), cd <dir>(è¿›å…¥ç›®å½•), up(ä¸Šçº§ç›®å½•), info <file>(æ–‡ä»¶ä¿¡æ¯), search <pattern>(æœç´¢), quit(é€€å‡º)")
        
        while self.running:
            try:
                print(f"\nå½“å‰ç›®å½•: {self.current_dir}")
                command = input("è¯·è¾“å…¥å‘½ä»¤: ").strip().split()
                
                if not command:
                    continue
                
                cmd = command[0].lower()
                
                if cmd == 'ls':
                    self.list_directory()
                elif cmd == 'cd' and len(command) > 1:
                    self.change_directory(command[1])
                elif cmd == 'up':
                    self.go_up()
                elif cmd == 'info' and len(command) > 1:
                    self.show_file_info(command[1])
                elif cmd == 'search' and len(command) > 1:
                    self.search_files(command[1])
                elif cmd == 'quit':
                    self.running = False
                else:
                    print("æ— æ•ˆå‘½ä»¤æˆ–ç¼ºå°‘å‚æ•°")
                    
            except KeyboardInterrupt:
                print("\né€€å‡ºæ–‡ä»¶æµè§ˆå™¨")
                break
            except Exception as e:
                print(f"é”™è¯¯: {e}")
    
    def list_directory(self):
        """åˆ—å‡ºå½“å‰ç›®å½•å†…å®¹"""
        try:
            items = list(self.current_dir.iterdir())
            items.sort(key=lambda x: (x.is_file(), x.name.lower()))
            
            print(f"\nç›®å½•å†…å®¹ ({len(items)} é¡¹):")
            for item in items:
                if item.is_dir():
                    print(f"  ğŸ“ {item.name}/")
                else:
                    size = item.stat().st_size
                    print(f"  ğŸ“„ {item.name} ({self._format_size(size)})")
                    
        except PermissionError:
            print("æ²¡æœ‰æƒé™è®¿é—®æ­¤ç›®å½•")
    
    def change_directory(self, dirname: str):
        """åˆ‡æ¢ç›®å½•"""
        try:
            new_dir = self.current_dir / dirname
            if new_dir.exists() and new_dir.is_dir():
                self.current_dir = new_dir.resolve()
                print(f"å·²è¿›å…¥ç›®å½•: {self.current_dir}")
            else:
                print(f"ç›®å½•ä¸å­˜åœ¨: {dirname}")
        except Exception as e:
            print(f"æ— æ³•è¿›å…¥ç›®å½•: {e}")
    
    def go_up(self):
        """è¿”å›ä¸Šçº§ç›®å½•"""
        parent = self.current_dir.parent
        if parent != self.current_dir:  # ä¸æ˜¯æ ¹ç›®å½•
            self.current_dir = parent
            print(f"å·²è¿”å›ä¸Šçº§ç›®å½•: {self.current_dir}")
        else:
            print("å·²åœ¨æ ¹ç›®å½•")
    
    def show_file_info(self, filename: str):
        """æ˜¾ç¤ºæ–‡ä»¶è¯¦ç»†ä¿¡æ¯"""
        try:
            file_path = self.current_dir / filename
            if not file_path.exists():
                print(f"æ–‡ä»¶ä¸å­˜åœ¨: {filename}")
                return
            
            stat = file_path.stat()
            print(f"\næ–‡ä»¶ä¿¡æ¯: {filename}")
            print(f"  è·¯å¾„: {file_path}")
            print(f"  ç±»å‹: {'ç›®å½•' if file_path.is_dir() else 'æ–‡ä»¶'}")
            print(f"  å¤§å°: {self._format_size(stat.st_size)}")
            print(f"  åˆ›å»ºæ—¶é—´: {datetime.fromtimestamp(stat.st_ctime)}")
            print(f"  ä¿®æ”¹æ—¶é—´: {datetime.fromtimestamp(stat.st_mtime)}")
            print(f"  è®¿é—®æ—¶é—´: {datetime.fromtimestamp(stat.st_atime)}")
            
            if file_path.is_file():
                # å°è¯•ç¡®å®šæ–‡ä»¶ç±»å‹
                mime_type, _ = mimetypes.guess_type(str(file_path))
                if mime_type:
                    print(f"  MIMEç±»å‹: {mime_type}")
                
                # å¦‚æœæ˜¯æ–‡æœ¬æ–‡ä»¶ï¼Œæ˜¾ç¤ºå‰å‡ è¡Œ
                if mime_type and mime_type.startswith('text'):
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            lines = f.readlines()[:5]
                        print(f"  å†…å®¹é¢„è§ˆ (å‰5è¡Œ):")
                        for i, line in enumerate(lines, 1):
                            print(f"    {i}: {line.rstrip()}")
                    except:
                        print("  æ— æ³•é¢„è§ˆæ–‡ä»¶å†…å®¹")
                        
        except Exception as e:
            print(f"è·å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥: {e}")
    
    def search_files(self, pattern: str):
        """æœç´¢æ–‡ä»¶"""
        try:
            print(f"\næœç´¢æ¨¡å¼: {pattern}")
            matches = []
            
            # åœ¨å½“å‰ç›®å½•åŠå­ç›®å½•ä¸­æœç´¢
            for item in self.current_dir.rglob('*'):
                if pattern.lower() in item.name.lower():
                    matches.append(item)
            
            if matches:
                print(f"æ‰¾åˆ° {len(matches)} ä¸ªåŒ¹é…é¡¹:")
                for match in matches[:20]:  # é™åˆ¶æ˜¾ç¤ºæ•°é‡
                    rel_path = match.relative_to(self.current_dir)
                    item_type = "ğŸ“" if match.is_dir() else "ğŸ“„"
                    print(f"  {item_type} {rel_path}")
                
                if len(matches) > 20:
                    print(f"  ... è¿˜æœ‰ {len(matches) - 20} ä¸ªåŒ¹é…é¡¹")
            else:
                print("æœªæ‰¾åˆ°åŒ¹é…çš„æ–‡ä»¶")
                
        except Exception as e:
            print(f"æœç´¢å¤±è´¥: {e}")
    
    def _format_size(self, size: int) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
        for unit in ['B', 'KB', 'MB', 'GB']:
            if size < 1024:
                return f"{size:.1f} {unit}"
            size /= 1024
        return f"{size:.1f} TB"

def file_explorer_demo():
    """æ–‡ä»¶æµè§ˆå™¨æ¼”ç¤ºï¼ˆéäº¤äº’å¼ï¼‰"""
    print("æ–‡ä»¶ç³»ç»Ÿæµè§ˆå™¨æ¼”ç¤º")
    
    # åˆ›å»ºæµ‹è¯•ç›®å½•ç»“æ„
    test_dir = Path('test_explorer')
    test_dir.mkdir(exist_ok=True)
    
    # åˆ›å»ºå­ç›®å½•å’Œæ–‡ä»¶
    (test_dir / 'subdir1').mkdir(exist_ok=True)
    (test_dir / 'subdir2').mkdir(exist_ok=True)
    
    (test_dir / 'file1.txt').write_text('è¿™æ˜¯æµ‹è¯•æ–‡ä»¶1')
    (test_dir / 'file2.py').write_text('print("Hello, World!")')
    (test_dir / 'subdir1' / 'nested_file.md').write_text('# åµŒå¥—æ–‡ä»¶')
    
    # åˆ›å»ºæµè§ˆå™¨å®ä¾‹
    explorer = FileExplorer(str(test_dir))
    
    print(f"\næ¼”ç¤ºç›®å½•ç»“æ„: {test_dir}")
    explorer.list_directory()
    
    print("\næ–‡ä»¶ä¿¡æ¯æ¼”ç¤º:")
    explorer.show_file_info('file1.txt')
    
    print("\næœç´¢æ¼”ç¤º:")
    explorer.search_files('file')
    
    # æ¸…ç†
    shutil.rmtree(test_dir)
    print(f"\nå·²æ¸…ç†æµ‹è¯•ç›®å½•: {test_dir}")
    
    print("\næ³¨æ„: åœ¨å®é™…ä½¿ç”¨ä¸­ï¼Œå¯ä»¥è°ƒç”¨ explorer.run() è¿›å…¥äº¤äº’æ¨¡å¼")

file_explorer_demo()

# ç»ƒä¹  4.2: ç›®å½•åŒæ­¥å·¥å…·
print("\n\nç»ƒä¹  4.2: ç›®å½•åŒæ­¥å·¥å…·")

class DirectorySynchronizer:
    """ç›®å½•åŒæ­¥å·¥å…·"""
    
    def __init__(self, source_dir: str, target_dir: str):
        self.source_dir = Path(source_dir)
        self.target_dir = Path(target_dir)
        self.sync_log = []
    
    def sync(self, delete_extra: bool = False) -> dict:
        """åŒæ­¥ç›®å½•
        
        Args:
            delete_extra: æ˜¯å¦åˆ é™¤ç›®æ ‡ç›®å½•ä¸­å¤šä½™çš„æ–‡ä»¶
            
        Returns:
            åŒæ­¥ç»“æœç»Ÿè®¡
        """
        stats = {
            'copied': 0,
            'updated': 0,
            'deleted': 0,
            'errors': 0
        }
        
        try:
            # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
            self.target_dir.mkdir(parents=True, exist_ok=True)
            
            # åŒæ­¥æºç›®å½•åˆ°ç›®æ ‡ç›®å½•
            self._sync_directory(self.source_dir, self.target_dir, stats)
            
            # åˆ é™¤ç›®æ ‡ç›®å½•ä¸­å¤šä½™çš„æ–‡ä»¶
            if delete_extra:
                self._delete_extra_files(self.source_dir, self.target_dir, stats)
            
        except Exception as e:
            self.sync_log.append(f"åŒæ­¥å¤±è´¥: {e}")
            stats['errors'] += 1
        
        return stats
    
    def _sync_directory(self, source: Path, target: Path, stats: dict):
        """é€’å½’åŒæ­¥ç›®å½•"""
        for source_item in source.iterdir():
            target_item = target / source_item.name
            
            try:
                if source_item.is_dir():
                    # åˆ›å»ºç›®å½•
                    target_item.mkdir(exist_ok=True)
                    # é€’å½’åŒæ­¥å­ç›®å½•
                    self._sync_directory(source_item, target_item, stats)
                else:
                    # åŒæ­¥æ–‡ä»¶
                    self._sync_file(source_item, target_item, stats)
                    
            except Exception as e:
                self.sync_log.append(f"åŒæ­¥ {source_item} å¤±è´¥: {e}")
                stats['errors'] += 1
    
    def _sync_file(self, source_file: Path, target_file: Path, stats: dict):
        """åŒæ­¥å•ä¸ªæ–‡ä»¶"""
        try:
            # æ£€æŸ¥ç›®æ ‡æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not target_file.exists():
                # å¤åˆ¶æ–°æ–‡ä»¶
                shutil.copy2(source_file, target_file)
                self.sync_log.append(f"å¤åˆ¶: {source_file} -> {target_file}")
                stats['copied'] += 1
            else:
                # æ¯”è¾ƒæ–‡ä»¶ä¿®æ”¹æ—¶é—´å’Œå¤§å°
                source_stat = source_file.stat()
                target_stat = target_file.stat()
                
                if (source_stat.st_mtime > target_stat.st_mtime or 
                    source_stat.st_size != target_stat.st_size):
                    # æ›´æ–°æ–‡ä»¶
                    shutil.copy2(source_file, target_file)
                    self.sync_log.append(f"æ›´æ–°: {source_file} -> {target_file}")
                    stats['updated'] += 1
                    
        except Exception as e:
            self.sync_log.append(f"åŒæ­¥æ–‡ä»¶ {source_file} å¤±è´¥: {e}")
            stats['errors'] += 1
    
    def _delete_extra_files(self, source: Path, target: Path, stats: dict):
        """åˆ é™¤ç›®æ ‡ç›®å½•ä¸­å¤šä½™çš„æ–‡ä»¶"""
        try:
            for target_item in target.iterdir():
                source_item = source / target_item.name
                
                if not source_item.exists():
                    # åˆ é™¤å¤šä½™çš„æ–‡ä»¶æˆ–ç›®å½•
                    if target_item.is_dir():
                        shutil.rmtree(target_item)
                    else:
                        target_item.unlink()
                    
                    self.sync_log.append(f"åˆ é™¤: {target_item}")
                    stats['deleted'] += 1
                elif target_item.is_dir() and source_item.is_dir():
                    # é€’å½’å¤„ç†å­ç›®å½•
                    self._delete_extra_files(source_item, target_item, stats)
                    
        except Exception as e:
            self.sync_log.append(f"åˆ é™¤å¤šä½™æ–‡ä»¶å¤±è´¥: {e}")
            stats['errors'] += 1
    
    def get_sync_log(self) -> list:
        """è·å–åŒæ­¥æ—¥å¿—"""
        return self.sync_log.copy()
    
    def clear_log(self):
        """æ¸…ç©ºåŒæ­¥æ—¥å¿—"""
        self.sync_log.clear()

def directory_sync_demo():
    """ç›®å½•åŒæ­¥æ¼”ç¤º"""
    print("ç›®å½•åŒæ­¥å·¥å…·æ¼”ç¤º")
    
    # åˆ›å»ºæºç›®å½•å’Œæ–‡ä»¶
    source_dir = Path('sync_source')
    target_dir = Path('sync_target')
    
    # æ¸…ç†æ—§çš„æµ‹è¯•ç›®å½•
    for dir_path in [source_dir, target_dir]:
        if dir_path.exists():
            shutil.rmtree(dir_path)
    
    # åˆ›å»ºæºç›®å½•ç»“æ„
    source_dir.mkdir()
    (source_dir / 'subdir1').mkdir()
    (source_dir / 'subdir2').mkdir()
    
    # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
    (source_dir / 'file1.txt').write_text('æ–‡ä»¶1å†…å®¹')
    (source_dir / 'file2.txt').write_text('æ–‡ä»¶2å†…å®¹')
    (source_dir / 'subdir1' / 'nested1.txt').write_text('åµŒå¥—æ–‡ä»¶1')
    (source_dir / 'subdir2' / 'nested2.txt').write_text('åµŒå¥—æ–‡ä»¶2')
    
    print(f"å·²åˆ›å»ºæºç›®å½•: {source_dir}")
    
    # ç¬¬ä¸€æ¬¡åŒæ­¥
    print("\n1. é¦–æ¬¡åŒæ­¥")
    synchronizer = DirectorySynchronizer(str(source_dir), str(target_dir))
    stats = synchronizer.sync()
    
    print(f"åŒæ­¥ç»“æœ: {stats}")
    print("åŒæ­¥æ—¥å¿—:")
    for log_entry in synchronizer.get_sync_log():
        print(f"  {log_entry}")
    
    # éªŒè¯ç›®æ ‡ç›®å½•
    print(f"\nç›®æ ‡ç›®å½•å†…å®¹:")
    for item in target_dir.rglob('*'):
        if item.is_file():
            rel_path = item.relative_to(target_dir)
            print(f"  ğŸ“„ {rel_path}")
    
    # ä¿®æ”¹æºæ–‡ä»¶
    print("\n2. ä¿®æ”¹æºæ–‡ä»¶åå†æ¬¡åŒæ­¥")
    import time
    time.sleep(1)  # ç¡®ä¿ä¿®æ”¹æ—¶é—´ä¸åŒ
    
    (source_dir / 'file1.txt').write_text('æ–‡ä»¶1ä¿®æ”¹åçš„å†…å®¹')
    (source_dir / 'new_file.txt').write_text('æ–°æ–‡ä»¶å†…å®¹')
    
    synchronizer.clear_log()
    stats = synchronizer.sync()
    
    print(f"åŒæ­¥ç»“æœ: {stats}")
    print("åŒæ­¥æ—¥å¿—:")
    for log_entry in synchronizer.get_sync_log():
        print(f"  {log_entry}")
    
    # åœ¨ç›®æ ‡ç›®å½•æ·»åŠ é¢å¤–æ–‡ä»¶
    print("\n3. æµ‹è¯•åˆ é™¤å¤šä½™æ–‡ä»¶")
    (target_dir / 'extra_file.txt').write_text('å¤šä½™æ–‡ä»¶')
    
    synchronizer.clear_log()
    stats = synchronizer.sync(delete_extra=True)
    
    print(f"åŒæ­¥ç»“æœ: {stats}")
    print("åŒæ­¥æ—¥å¿—:")
    for log_entry in synchronizer.get_sync_log():
        print(f"  {log_entry}")
    
    # æ¸…ç†
    shutil.rmtree(source_dir)
    shutil.rmtree(target_dir)
    print("\nå·²æ¸…ç†æµ‹è¯•ç›®å½•")

directory_sync_demo()

# ============================================================================
# 5. é«˜çº§æ–‡ä»¶æ“ä½œç»ƒä¹ ç­”æ¡ˆ
# ============================================================================

print("\n\n5. é«˜çº§æ–‡ä»¶æ“ä½œç»ƒä¹ ç­”æ¡ˆ")
print("-" * 30)

# ç»ƒä¹  5.1: å¤§æ–‡ä»¶å¤„ç†å™¨
print("\nç»ƒä¹  5.1: å¤§æ–‡ä»¶å¤„ç†å™¨")

class LargeFileProcessor:
    """å¤§æ–‡ä»¶å¤„ç†å™¨"""
    
    def __init__(self, chunk_size: int = 8192):
        self.chunk_size = chunk_size
    
    def split_file(self, input_file: str, chunk_size_mb: int = 10) -> list:
        """åˆ†å‰²å¤§æ–‡ä»¶
        
        Args:
            input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
            chunk_size_mb: æ¯ä¸ªåˆ†å—çš„å¤§å°ï¼ˆMBï¼‰
            
        Returns:
            åˆ†å—æ–‡ä»¶åˆ—è¡¨
        """
        chunk_size_bytes = chunk_size_mb * 1024 * 1024
        chunk_files = []
        
        try:
            input_path = Path(input_file)
            base_name = input_path.stem
            extension = input_path.suffix
            
            with open(input_file, 'rb') as infile:
                chunk_num = 0
                
                while True:
                    chunk_data = infile.read(chunk_size_bytes)
                    if not chunk_data:
                        break
                    
                    chunk_filename = f"{base_name}.part{chunk_num:03d}{extension}"
                    chunk_files.append(chunk_filename)
                    
                    with open(chunk_filename, 'wb') as chunk_file:
                        chunk_file.write(chunk_data)
                    
                    chunk_num += 1
                    print(f"åˆ›å»ºåˆ†å—: {chunk_filename} ({len(chunk_data)} å­—èŠ‚)")
            
            return chunk_files
            
        except Exception as e:
            print(f"åˆ†å‰²æ–‡ä»¶å¤±è´¥: {e}")
            return []
    
    def merge_files(self, chunk_files: list, output_file: str) -> bool:
        """åˆå¹¶åˆ†å—æ–‡ä»¶
        
        Args:
            chunk_files: åˆ†å—æ–‡ä»¶åˆ—è¡¨
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            with open(output_file, 'wb') as outfile:
                for chunk_file in chunk_files:
                    if not Path(chunk_file).exists():
                        print(f"åˆ†å—æ–‡ä»¶ä¸å­˜åœ¨: {chunk_file}")
                        return False
                    
                    with open(chunk_file, 'rb') as infile:
                        while True:
                            chunk = infile.read(self.chunk_size)
                            if not chunk:
                                break
                            outfile.write(chunk)
                    
                    print(f"åˆå¹¶åˆ†å—: {chunk_file}")
            
            return True
            
        except Exception as e:
            print(f"åˆå¹¶æ–‡ä»¶å¤±è´¥: {e}")
            return False
    
    def calculate_file_hash(self, filename: str, algorithm: str = 'md5') -> str:
        """è®¡ç®—æ–‡ä»¶å“ˆå¸Œå€¼
        
        Args:
            filename: æ–‡ä»¶è·¯å¾„
            algorithm: å“ˆå¸Œç®—æ³• (md5, sha1, sha256)
            
        Returns:
            å“ˆå¸Œå€¼
        """
        import hashlib
        
        try:
            if algorithm == 'md5':
                hasher = hashlib.md5()
            elif algorithm == 'sha1':
                hasher = hashlib.sha1()
            elif algorithm == 'sha256':
                hasher = hashlib.sha256()
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„å“ˆå¸Œç®—æ³•: {algorithm}")
            
            with open(filename, 'rb') as f:
                while True:
                    chunk = f.read(self.chunk_size)
                    if not chunk:
                        break
                    hasher.update(chunk)
            
            return hasher.hexdigest()
            
        except Exception as e:
            print(f"è®¡ç®—å“ˆå¸Œå¤±è´¥: {e}")
            return ""
    
    def verify_file_integrity(self, original_file: str, restored_file: str) -> bool:
        """éªŒè¯æ–‡ä»¶å®Œæ•´æ€§"""
        try:
            original_hash = self.calculate_file_hash(original_file)
            restored_hash = self.calculate_file_hash(restored_file)
            
            return original_hash == restored_hash and original_hash != ""
            
        except Exception:
            return False

def large_file_demo():
    """å¤§æ–‡ä»¶å¤„ç†æ¼”ç¤º"""
    print("å¤§æ–‡ä»¶å¤„ç†å™¨æ¼”ç¤º")
    
    # åˆ›å»ºä¸€ä¸ªè¾ƒå¤§çš„æµ‹è¯•æ–‡ä»¶
    test_file = 'large_test_file.txt'
    print(f"åˆ›å»ºæµ‹è¯•æ–‡ä»¶: {test_file}")
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ®ï¼ˆçº¦1MBï¼‰
    test_data = "è¿™æ˜¯æµ‹è¯•æ•°æ®è¡Œã€‚" * 1000 + "\n"
    with open(test_file, 'w', encoding='utf-8') as f:
        for i in range(100):  # çº¦100KB
            f.write(f"ç¬¬{i+1}è¡Œ: {test_data}")
    
    file_size = os.path.getsize(test_file)
    print(f"æµ‹è¯•æ–‡ä»¶å¤§å°: {file_size / 1024:.1f} KB")
    
    # åˆ›å»ºå¤„ç†å™¨
    processor = LargeFileProcessor()
    
    # è®¡ç®—åŸå§‹æ–‡ä»¶å“ˆå¸Œ
    original_hash = processor.calculate_file_hash(test_file)
    print(f"åŸå§‹æ–‡ä»¶MD5: {original_hash}")
    
    # åˆ†å‰²æ–‡ä»¶
    print("\nåˆ†å‰²æ–‡ä»¶:")
    chunk_files = processor.split_file(test_file, chunk_size_mb=1)  # 1MBåˆ†å—
    
    if chunk_files:
        print(f"æ–‡ä»¶å·²åˆ†å‰²ä¸º {len(chunk_files)} ä¸ªåˆ†å—")
        
        # æ˜¾ç¤ºåˆ†å—ä¿¡æ¯
        total_chunk_size = 0
        for chunk_file in chunk_files:
            chunk_size = os.path.getsize(chunk_file)
            total_chunk_size += chunk_size
            print(f"  {chunk_file}: {chunk_size} å­—èŠ‚")
        
        print(f"åˆ†å—æ€»å¤§å°: {total_chunk_size} å­—èŠ‚")
        
        # åˆå¹¶æ–‡ä»¶
        print("\nåˆå¹¶æ–‡ä»¶:")
        restored_file = 'restored_file.txt'
        success = processor.merge_files(chunk_files, restored_file)
        
        if success:
            print(f"æ–‡ä»¶åˆå¹¶æˆåŠŸ: {restored_file}")
            
            # éªŒè¯å®Œæ•´æ€§
            restored_hash = processor.calculate_file_hash(restored_file)
            print(f"æ¢å¤æ–‡ä»¶MD5: {restored_hash}")
            
            if processor.verify_file_integrity(test_file, restored_file):
                print("âœ“ æ–‡ä»¶å®Œæ•´æ€§éªŒè¯æˆåŠŸ")
            else:
                print("âœ— æ–‡ä»¶å®Œæ•´æ€§éªŒè¯å¤±è´¥")
            
            # æ¯”è¾ƒæ–‡ä»¶å¤§å°
            original_size = os.path.getsize(test_file)
            restored_size = os.path.getsize(restored_file)
            print(f"åŸå§‹æ–‡ä»¶å¤§å°: {original_size} å­—èŠ‚")
            print(f"æ¢å¤æ–‡ä»¶å¤§å°: {restored_size} å­—èŠ‚")
        
        # æ¸…ç†åˆ†å—æ–‡ä»¶
        for chunk_file in chunk_files:
            if os.path.exists(chunk_file):
                os.remove(chunk_file)
        print("\nå·²æ¸…ç†åˆ†å—æ–‡ä»¶")
        
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        if os.path.exists(restored_file):
            os.remove(restored_file)
    
    # æ¸…ç†åŸå§‹æµ‹è¯•æ–‡ä»¶
    os.remove(test_file)
    print("å·²æ¸…ç†æµ‹è¯•æ–‡ä»¶")

large_file_demo()

# ç»ƒä¹  5.2: æ–‡ä»¶ç›‘æ§å™¨
print("\n\nç»ƒä¹  5.2: æ–‡ä»¶ç›‘æ§å™¨")

class FileMonitor:
    """ç®€å•çš„æ–‡ä»¶ç›‘æ§å™¨"""
    
    def __init__(self, watch_directory: str):
        self.watch_directory = Path(watch_directory)
        self.file_states = {}
        self.monitoring = False
        self.callbacks = {
            'created': [],
            'modified': [],
            'deleted': []
        }
    
    def add_callback(self, event_type: str, callback):
        """æ·»åŠ äº‹ä»¶å›è°ƒå‡½æ•°
        
        Args:
            event_type: äº‹ä»¶ç±»å‹ ('created', 'modified', 'deleted')
            callback: å›è°ƒå‡½æ•°ï¼Œæ¥æ”¶æ–‡ä»¶è·¯å¾„ä½œä¸ºå‚æ•°
        """
        if event_type in self.callbacks:
            self.callbacks[event_type].append(callback)
    
    def scan_directory(self) -> dict:
        """æ‰«æç›®å½•ï¼Œè¿”å›å½“å‰æ–‡ä»¶çŠ¶æ€"""
        current_states = {}
        
        try:
            if self.watch_directory.exists():
                for file_path in self.watch_directory.rglob('*'):
                    if file_path.is_file():
                        stat = file_path.stat()
                        current_states[str(file_path)] = {
                            'size': stat.st_size,
                            'mtime': stat.st_mtime
                        }
        except Exception as e:
            print(f"æ‰«æç›®å½•å¤±è´¥: {e}")
        
        return current_states
    
    def detect_changes(self):
        """æ£€æµ‹æ–‡ä»¶å˜åŒ–"""
        current_states = self.scan_directory()
        
        # æ£€æµ‹æ–°æ–‡ä»¶å’Œä¿®æ”¹çš„æ–‡ä»¶
        for file_path, current_state in current_states.items():
            if file_path not in self.file_states:
                # æ–°æ–‡ä»¶
                self._trigger_callbacks('created', file_path)
            else:
                # æ£€æŸ¥æ˜¯å¦ä¿®æ”¹
                old_state = self.file_states[file_path]
                if (current_state['size'] != old_state['size'] or 
                    current_state['mtime'] != old_state['mtime']):
                    self._trigger_callbacks('modified', file_path)
        
        # æ£€æµ‹åˆ é™¤çš„æ–‡ä»¶
        for file_path in self.file_states:
            if file_path not in current_states:
                self._trigger_callbacks('deleted', file_path)
        
        # æ›´æ–°æ–‡ä»¶çŠ¶æ€
        self.file_states = current_states
    
    def _trigger_callbacks(self, event_type: str, file_path: str):
        """è§¦å‘å›è°ƒå‡½æ•°"""
        for callback in self.callbacks[event_type]:
            try:
                callback(file_path)
            except Exception as e:
                print(f"å›è°ƒå‡½æ•°æ‰§è¡Œå¤±è´¥: {e}")
    
    def start_monitoring(self, interval: float = 1.0):
        """å¼€å§‹ç›‘æ§ï¼ˆç®€åŒ–ç‰ˆï¼Œä½¿ç”¨è½®è¯¢ï¼‰
        
        Args:
            interval: æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰
        """
        import time
        
        self.monitoring = True
        print(f"å¼€å§‹ç›‘æ§ç›®å½•: {self.watch_directory}")
        
        # åˆå§‹æ‰«æ
        self.file_states = self.scan_directory()
        
        try:
            while self.monitoring:
                time.sleep(interval)
                self.detect_changes()
        except KeyboardInterrupt:
            print("\nç›‘æ§å·²åœæ­¢")
        finally:
            self.monitoring = False
    
    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        self.monitoring = False

def file_monitor_demo():
    """æ–‡ä»¶ç›‘æ§å™¨æ¼”ç¤º"""
    print("æ–‡ä»¶ç›‘æ§å™¨æ¼”ç¤º")
    
    # åˆ›å»ºç›‘æ§ç›®å½•
    watch_dir = Path('monitor_test')
    watch_dir.mkdir(exist_ok=True)
    
    # åˆ›å»ºç›‘æ§å™¨
    monitor = FileMonitor(str(watch_dir))
    
    # æ·»åŠ å›è°ƒå‡½æ•°
    def on_file_created(file_path):
        print(f"ğŸ“„ æ–‡ä»¶åˆ›å»º: {Path(file_path).name}")
    
    def on_file_modified(file_path):
        print(f"âœï¸ æ–‡ä»¶ä¿®æ”¹: {Path(file_path).name}")
    
    def on_file_deleted(file_path):
        print(f"ğŸ—‘ï¸ æ–‡ä»¶åˆ é™¤: {Path(file_path).name}")
    
    monitor.add_callback('created', on_file_created)
    monitor.add_callback('modified', on_file_modified)
    monitor.add_callback('deleted', on_file_deleted)
    
    # æ¨¡æ‹Ÿæ–‡ä»¶æ“ä½œ
    print("\næ¨¡æ‹Ÿæ–‡ä»¶æ“ä½œ:")
    
    # åˆå§‹æ‰«æ
    monitor.file_states = monitor.scan_directory()
    print(f"åˆå§‹æ–‡ä»¶æ•°é‡: {len(monitor.file_states)}")
    
    # åˆ›å»ºæ–‡ä»¶
    test_file1 = watch_dir / 'test1.txt'
    test_file1.write_text('æµ‹è¯•æ–‡ä»¶1')
    monitor.detect_changes()
    
    # ä¿®æ”¹æ–‡ä»¶
    import time
    time.sleep(0.1)  # ç¡®ä¿ä¿®æ”¹æ—¶é—´ä¸åŒ
    test_file1.write_text('æµ‹è¯•æ–‡ä»¶1 - å·²ä¿®æ”¹')
    monitor.detect_changes()
    
    # åˆ›å»ºå¦ä¸€ä¸ªæ–‡ä»¶
    test_file2 = watch_dir / 'test2.txt'
    test_file2.write_text('æµ‹è¯•æ–‡ä»¶2')
    monitor.detect_changes()
    
    # åˆ é™¤æ–‡ä»¶
    test_file1.unlink()
    monitor.detect_changes()
    
    # æ¸…ç†
    shutil.rmtree(watch_dir)
    print("\nå·²æ¸…ç†æµ‹è¯•ç›®å½•")
    
    print("\næ³¨æ„: åœ¨å®é™…ä½¿ç”¨ä¸­ï¼Œå¯ä»¥è°ƒç”¨ monitor.start_monitoring() è¿›å…¥æŒç»­ç›‘æ§æ¨¡å¼")

file_monitor_demo()

# ============================================================================
# 6. ç»¼åˆåº”ç”¨ç»ƒä¹ ç­”æ¡ˆ
# ============================================================================

print("\n\n6. ç»¼åˆåº”ç”¨ç»ƒä¹ ç­”æ¡ˆ")
print("-" * 30)

# ç»ƒä¹  6.1: æ–‡ä»¶ç®¡ç†ç³»ç»Ÿ
print("\nç»ƒä¹  6.1: æ–‡ä»¶ç®¡ç†ç³»ç»Ÿ")

class FileManager:
    """æ–‡ä»¶ç®¡ç†ç³»ç»Ÿ"""
    
    def __init__(self, base_directory: str):
        self.base_dir = Path(base_directory)
        self.base_dir.mkdir(parents=True, exist_ok=True)
        self.operation_log = []
    
    def create_file(self, filename: str, content: str = "") -> bool:
        """åˆ›å»ºæ–‡ä»¶"""
        try:
            file_path = self.base_dir / filename
            file_path.parent.mkdir(parents=True, exist_ok=True)
            
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            self._log_operation(f"åˆ›å»ºæ–‡ä»¶: {filename}")
            return True
            
        except Exception as e:
            self._log_operation(f"åˆ›å»ºæ–‡ä»¶å¤±è´¥ {filename}: {e}")
            return False
    
    def read_file(self, filename: str) -> str:
        """è¯»å–æ–‡ä»¶å†…å®¹"""
        try:
            file_path = self.base_dir / filename
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            self._log_operation(f"è¯»å–æ–‡ä»¶: {filename}")
            return content
            
        except Exception as e:
            self._log_operation(f"è¯»å–æ–‡ä»¶å¤±è´¥ {filename}: {e}")
            return ""
    
    def update_file(self, filename: str, content: str) -> bool:
        """æ›´æ–°æ–‡ä»¶å†…å®¹"""
        try:
            file_path = self.base_dir / filename
            if not file_path.exists():
                self._log_operation(f"æ›´æ–°æ–‡ä»¶å¤±è´¥ {filename}: æ–‡ä»¶ä¸å­˜åœ¨")
                return False
            
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            self._log_operation(f"æ›´æ–°æ–‡ä»¶: {filename}")
            return True
            
        except Exception as e:
            self._log_operation(f"æ›´æ–°æ–‡ä»¶å¤±è´¥ {filename}: {e}")
            return False
    
    def delete_file(self, filename: str) -> bool:
        """åˆ é™¤æ–‡ä»¶"""
        try:
            file_path = self.base_dir / filename
            if file_path.exists():
                file_path.unlink()
                self._log_operation(f"åˆ é™¤æ–‡ä»¶: {filename}")
                return True
            else:
                self._log_operation(f"åˆ é™¤æ–‡ä»¶å¤±è´¥ {filename}: æ–‡ä»¶ä¸å­˜åœ¨")
                return False
                
        except Exception as e:
            self._log_operation(f"åˆ é™¤æ–‡ä»¶å¤±è´¥ {filename}: {e}")
            return False
    
    def list_files(self, pattern: str = "*") -> list:
        """åˆ—å‡ºæ–‡ä»¶"""
        try:
            files = []
            for file_path in self.base_dir.rglob(pattern):
                if file_path.is_file():
                    rel_path = file_path.relative_to(self.base_dir)
                    files.append(str(rel_path))
            
            self._log_operation(f"åˆ—å‡ºæ–‡ä»¶: {pattern} (æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶)")
            return sorted(files)
            
        except Exception as e:
            self._log_operation(f"åˆ—å‡ºæ–‡ä»¶å¤±è´¥: {e}")
            return []
    
    def search_files(self, keyword: str) -> list:
        """æœç´¢æ–‡ä»¶å†…å®¹"""
        results = []
        
        try:
            for file_path in self.base_dir.rglob('*.txt'):
                if file_path.is_file():
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                        
                        if keyword.lower() in content.lower():
                            rel_path = file_path.relative_to(self.base_dir)
                            results.append(str(rel_path))
                            
                    except Exception:
                        continue  # è·³è¿‡æ— æ³•è¯»å–çš„æ–‡ä»¶
            
            self._log_operation(f"æœç´¢å…³é”®è¯ '{keyword}': æ‰¾åˆ° {len(results)} ä¸ªæ–‡ä»¶")
            return results
            
        except Exception as e:
            self._log_operation(f"æœç´¢å¤±è´¥: {e}")
            return []
    
    def backup_files(self, backup_dir: str) -> bool:
        """å¤‡ä»½æ–‡ä»¶"""
        try:
            backup_path = Path(backup_dir)
            backup_path.mkdir(parents=True, exist_ok=True)
            
            # åˆ›å»ºæ—¶é—´æˆ³ç›®å½•
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_subdir = backup_path / f"backup_{timestamp}"
            
            # å¤åˆ¶æ•´ä¸ªç›®å½•
            shutil.copytree(self.base_dir, backup_subdir)
            
            self._log_operation(f"å¤‡ä»½å®Œæˆ: {backup_subdir}")
            return True
            
        except Exception as e:
            self._log_operation(f"å¤‡ä»½å¤±è´¥: {e}")
            return False
    
    def get_file_info(self, filename: str) -> dict:
        """è·å–æ–‡ä»¶ä¿¡æ¯"""
        try:
            file_path = self.base_dir / filename
            if not file_path.exists():
                return {}
            
            stat = file_path.stat()
            info = {
                'name': filename,
                'size': stat.st_size,
                'created': datetime.fromtimestamp(stat.st_ctime),
                'modified': datetime.fromtimestamp(stat.st_mtime),
                'is_directory': file_path.is_dir()
            }
            
            if file_path.is_file():
                # å°è¯•è·å–MIMEç±»å‹
                mime_type, _ = mimetypes.guess_type(str(file_path))
                info['mime_type'] = mime_type
            
            self._log_operation(f"è·å–æ–‡ä»¶ä¿¡æ¯: {filename}")
            return info
            
        except Exception as e:
            self._log_operation(f"è·å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥ {filename}: {e}")
            return {}
    
    def _log_operation(self, message: str):
        """è®°å½•æ“ä½œæ—¥å¿—"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_entry = f"[{timestamp}] {message}"
        self.operation_log.append(log_entry)
        
        # é™åˆ¶æ—¥å¿—å¤§å°
        if len(self.operation_log) > 1000:
            self.operation_log = self.operation_log[-500:]
    
    def get_operation_log(self, limit: int = 50) -> list:
        """è·å–æ“ä½œæ—¥å¿—"""
        return self.operation_log[-limit:]
    
    def export_log(self, log_file: str) -> bool:
        """å¯¼å‡ºæ“ä½œæ—¥å¿—"""
        try:
            with open(log_file, 'w', encoding='utf-8') as f:
                for log_entry in self.operation_log:
                    f.write(log_entry + '\n')
            return True
        except Exception:
            return False

def file_manager_demo():
    """æ–‡ä»¶ç®¡ç†ç³»ç»Ÿæ¼”ç¤º"""
    print("æ–‡ä»¶ç®¡ç†ç³»ç»Ÿæ¼”ç¤º")
    
    # åˆ›å»ºæ–‡ä»¶ç®¡ç†å™¨
    manager = FileManager('file_manager_test')
    
    # åˆ›å»ºæ–‡ä»¶
    print("\n1. åˆ›å»ºæ–‡ä»¶")
    manager.create_file('documents/readme.txt', 'è¿™æ˜¯ä¸€ä¸ªREADMEæ–‡ä»¶\nåŒ…å«é¡¹ç›®è¯´æ˜')
    manager.create_file('documents/notes.txt', 'å­¦ä¹ ç¬”è®°\nPythonæ–‡ä»¶æ“ä½œ')
    manager.create_file('scripts/hello.py', 'print("Hello, World!")')
    manager.create_file('data/config.json', '{"debug": true, "version": "1.0"}')
    
    # åˆ—å‡ºæ–‡ä»¶
    print("\n2. åˆ—å‡ºæ‰€æœ‰æ–‡ä»¶")
    files = manager.list_files()
    for file in files:
        print(f"  ğŸ“„ {file}")
    
    # è¯»å–æ–‡ä»¶
    print("\n3. è¯»å–æ–‡ä»¶å†…å®¹")
    content = manager.read_file('documents/readme.txt')
    print(f"readme.txt å†…å®¹:\n{content}")
    
    # æ›´æ–°æ–‡ä»¶
    print("\n4. æ›´æ–°æ–‡ä»¶")
    new_content = content + "\n\næ›´æ–°æ—¶é—´: " + datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    manager.update_file('documents/readme.txt', new_content)
    
    # æœç´¢æ–‡ä»¶
    print("\n5. æœç´¢æ–‡ä»¶å†…å®¹")
    search_results = manager.search_files('Python')
    print(f"åŒ…å«'Python'çš„æ–‡ä»¶: {search_results}")
    
    # è·å–æ–‡ä»¶ä¿¡æ¯
    print("\n6. è·å–æ–‡ä»¶ä¿¡æ¯")
    file_info = manager.get_file_info('documents/readme.txt')
    if file_info:
        print(f"æ–‡ä»¶ä¿¡æ¯:")
        for key, value in file_info.items():
            print(f"  {key}: {value}")
    
    # å¤‡ä»½æ–‡ä»¶
    print("\n7. å¤‡ä»½æ–‡ä»¶")
    backup_success = manager.backup_files('backups')
    print(f"å¤‡ä»½ç»“æœ: {'æˆåŠŸ' if backup_success else 'å¤±è´¥'}")
    
    # æ˜¾ç¤ºæ“ä½œæ—¥å¿—
    print("\n8. æ“ä½œæ—¥å¿—")
    logs = manager.get_operation_log(10)
    for log in logs:
        print(f"  {log}")
    
    # å¯¼å‡ºæ—¥å¿—
    log_file = 'operation_log.txt'
    if manager.export_log(log_file):
        print(f"\næ—¥å¿—å·²å¯¼å‡ºåˆ°: {log_file}")
    
    # æ¸…ç†
    shutil.rmtree('file_manager_test')
    if Path('backups').exists():
        shutil.rmtree('backups')
    if Path(log_file).exists():
        os.remove(log_file)
    print("\nå·²æ¸…ç†æµ‹è¯•æ–‡ä»¶")

file_manager_demo()

print("\n" + "=" * 50)
print("æ–‡ä»¶æ“ä½œç»ƒä¹ é¢˜å‚è€ƒç­”æ¡ˆ - å®Œæ•´ç‰ˆ")
print("åŒ…å«ï¼šåŸºç¡€æ–‡ä»¶æ“ä½œã€æ–‡æœ¬æ–‡ä»¶å¤„ç†ã€äºŒè¿›åˆ¶æ–‡ä»¶å¤„ç†ã€")
print("      æ–‡ä»¶ç³»ç»Ÿæ“ä½œã€é«˜çº§æ–‡ä»¶æ“ä½œã€ç»¼åˆåº”ç”¨")
print("=" * 50)

# ============================================================================
# æ–‡ä»¶æ“ä½œå­¦ä¹ è¦ç‚¹æ€»ç»“
# ============================================================================

print("\n\nğŸ“š æ–‡ä»¶æ“ä½œå­¦ä¹ è¦ç‚¹æ€»ç»“")
print("=" * 50)

print("""
ğŸ¯ æ ¸å¿ƒæ¦‚å¿µ:
1. æ–‡ä»¶å¯¹è±¡å’Œæ–‡ä»¶æ¨¡å¼
2. æ–‡æœ¬æ–‡ä»¶ vs äºŒè¿›åˆ¶æ–‡ä»¶
3. æ–‡ä»¶ç¼–ç å¤„ç†
4. è·¯å¾„æ“ä½œå’Œpathlib
5. å¼‚å¸¸å¤„ç†å’Œèµ„æºç®¡ç†

ğŸ“– åŸºç¡€æ“ä½œ:
1. æ–‡ä»¶æ‰“å¼€ã€è¯»å–ã€å†™å…¥ã€å…³é—­
2. æ–‡ä»¶æŒ‡é’ˆæ“ä½œ
3. ä¸Šä¸‹æ–‡ç®¡ç†å™¨ (withè¯­å¥)
4. æ–‡ä»¶æ¨¡å¼é€‰æ‹©

ğŸ“ æ–‡æœ¬æ–‡ä»¶å¤„ç†:
1. ç¼–ç å¤„ç† (UTF-8, GBKç­‰)
2. CSVæ–‡ä»¶è¯»å†™
3. JSONæ–‡ä»¶å¤„ç†
4. é…ç½®æ–‡ä»¶ç®¡ç†
5. æ—¥å¿—æ–‡ä»¶å¤„ç†

ğŸ”§ äºŒè¿›åˆ¶æ–‡ä»¶å¤„ç†:
1. å­—èŠ‚æ“ä½œ
2. æ–‡ä»¶æ ¼å¼è§£æ
3. åºåˆ—åŒ–å’Œååºåˆ—åŒ–
4. æ–‡ä»¶åŠ å¯†è§£å¯†
5. å›¾åƒå’Œåª’ä½“æ–‡ä»¶å¤„ç†

ğŸ“ æ–‡ä»¶ç³»ç»Ÿæ“ä½œ:
1. ç›®å½•åˆ›å»ºã€åˆ é™¤ã€éå†
2. æ–‡ä»¶å¤åˆ¶ã€ç§»åŠ¨ã€é‡å‘½å
3. æ–‡ä»¶å±æ€§å’Œæƒé™
4. è·¯å¾„æ“ä½œå’Œè§£æ
5. æ–‡ä»¶æœç´¢å’Œè¿‡æ»¤

ğŸš€ é«˜çº§ç‰¹æ€§:
1. å¤§æ–‡ä»¶å¤„ç†å’Œåˆ†å—æ“ä½œ
2. æ–‡ä»¶ç›‘æ§å’Œå˜åŒ–æ£€æµ‹
3. æ–‡ä»¶å‹ç¼©å’Œè§£å‹
4. ä¸´æ—¶æ–‡ä»¶å’Œæ–‡ä»¶é”
5. å¼‚æ­¥æ–‡ä»¶æ“ä½œ

ğŸ’¡ æœ€ä½³å®è·µ:
1. å§‹ç»ˆä½¿ç”¨withè¯­å¥ç®¡ç†æ–‡ä»¶èµ„æº
2. æ­£ç¡®å¤„ç†æ–‡ä»¶ç¼–ç 
3. é€‚å½“çš„å¼‚å¸¸å¤„ç†
4. å¤§æ–‡ä»¶åˆ†å—å¤„ç†
5. è·¯å¾„ä½¿ç”¨pathlibè€Œéå­—ç¬¦ä¸²æ‹¼æ¥
6. æ–‡ä»¶æ“ä½œå‰æ£€æŸ¥æƒé™å’Œå­˜åœ¨æ€§
7. æ•æ„Ÿæ•°æ®çš„å®‰å…¨å¤„ç†
8. å®šæœŸå¤‡ä»½é‡è¦æ–‡ä»¶

âš ï¸ å¸¸è§é™·é˜±:
1. å¿˜è®°å…³é—­æ–‡ä»¶å¥æŸ„
2. ç¼–ç é—®é¢˜å¯¼è‡´çš„ä¹±ç 
3. è·¯å¾„åˆ†éš”ç¬¦çš„è·¨å¹³å°é—®é¢˜
4. æ–‡ä»¶æƒé™ä¸è¶³
5. å¤§æ–‡ä»¶å†…å­˜æº¢å‡º
6. å¹¶å‘è®¿é—®å†²çª
7. æ–‡ä»¶é”å®šé—®é¢˜

ğŸ“ è¿›é˜¶å­¦ä¹ :
1. æ–‡ä»¶ç³»ç»Ÿç›‘æ§ (watchdogåº“)
2. å¼‚æ­¥æ–‡ä»¶æ“ä½œ (aiofiles)
3. æ•°æ®åº“æ–‡ä»¶æ“ä½œ
4. ç½‘ç»œæ–‡ä»¶ç³»ç»Ÿ
5. æ–‡ä»¶ç‰ˆæœ¬æ§åˆ¶
6. æ–‡ä»¶åŒæ­¥å’Œå¤‡ä»½ç­–ç•¥
""")

print("\nğŸ‰ æ­å–œï¼ä½ å·²ç»å®Œæˆäº†Pythonæ–‡ä»¶æ“ä½œçš„å…¨é¢å­¦ä¹ ï¼")
print("ç»§ç»­ç»ƒä¹ å’Œå®è·µï¼ŒæŒæ¡æ›´å¤šé«˜çº§æŠ€å·§ï¼")